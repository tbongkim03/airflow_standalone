[[34m2024-07-29T17:36:30.511+0900[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2024-07-29T17:36:30.511+0900[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2024-07-29T17:36:30.550+0900[0m] {[34mscheduler_job_runner.py:[0m799} INFO[0m - Starting the scheduler[0m
[[34m2024-07-29T17:36:30.551+0900[0m] {[34mscheduler_job_runner.py:[0m806} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-07-29T17:36:30.555+0900[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 306422[0m
[[34m2024-07-29T17:36:30.557+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T17:36:30.560+0900[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[2024-07-29T17:36:30.587+0900] {manager.py:393} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-07-29T17:36:30.921+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-11 04:10:00+00:00: scheduled__2024-07-11T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:16:23.138818+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:36:30.921+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-11 04:10:00+00:00, run_id=scheduled__2024-07-11T04:10:00+00:00, run_start_date=2024-07-29 08:16:24.075870+00:00, run_end_date=2024-07-29 08:36:30.921741+00:00, run_duration=1206.845871, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-11 04:10:00+00:00, data_interval_end=2024-07-12 04:10:00+00:00, dag_hash=6441f40e731f53180eb8b0797100add2[0m
[[34m2024-07-29T17:36:30.924+0900[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG movie is at (or above) max_active_runs (18 of 16), not creating any more runs[0m
[[34m2024-07-29T17:36:30.929+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-12 04:10:00+00:00: scheduled__2024-07-12T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:16:23.138832+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:36:30.930+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-12 04:10:00+00:00, run_id=scheduled__2024-07-12T04:10:00+00:00, run_start_date=2024-07-29 08:16:24.075884+00:00, run_end_date=2024-07-29 08:36:30.930104+00:00, run_duration=1206.85422, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-12 04:10:00+00:00, data_interval_end=2024-07-13 04:10:00+00:00, dag_hash=6441f40e731f53180eb8b0797100add2[0m
[[34m2024-07-29T17:36:30.932+0900[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG movie is at (or above) max_active_runs (17 of 16), not creating any more runs[0m
[[34m2024-07-29T17:36:30.940+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-13 04:10:00+00:00: scheduled__2024-07-13T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:16:23.138843+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:36:30.941+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-13 04:10:00+00:00, run_id=scheduled__2024-07-13T04:10:00+00:00, run_start_date=2024-07-29 08:16:24.075896+00:00, run_end_date=2024-07-29 08:36:30.941095+00:00, run_duration=1206.865199, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-13 04:10:00+00:00, data_interval_end=2024-07-14 04:10:00+00:00, dag_hash=6441f40e731f53180eb8b0797100add2[0m
[[34m2024-07-29T17:36:30.943+0900[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG movie is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
[[34m2024-07-29T17:36:31.034+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 8 tasks up for execution:
	<TaskInstance: movie.print_the_context scheduled__2024-07-10T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-22T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-23T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-23T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-24T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-24T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:36:31.035+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-29T17:36:31.035+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-29T17:36:31.035+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 8/16 running and queued tasks[0m
[[34m2024-07-29T17:36:31.035+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 9/16 running and queued tasks[0m
[[34m2024-07-29T17:36:31.035+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 10/16 running and queued tasks[0m
[[34m2024-07-29T17:36:31.035+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 11/16 running and queued tasks[0m
[[34m2024-07-29T17:36:31.036+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 12/16 running and queued tasks[0m
[[34m2024-07-29T17:36:31.036+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 13/16 running and queued tasks[0m
[[34m2024-07-29T17:36:31.036+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.print_the_context scheduled__2024-07-10T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-22T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-23T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-23T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-24T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-24T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:36:31.040+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-10T04:10:00+00:00', try_number=18, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:36:31.041+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-10T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:31.041+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-22T04:10:00+00:00', try_number=14, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:36:31.041+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-22T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:31.041+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-23T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:36:31.041+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-23T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:31.041+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-23T04:10:00+00:00', try_number=14, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:36:31.042+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-23T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:31.042+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-24T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:36:31.042+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-24T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:31.042+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-24T04:10:00+00:00', try_number=14, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:36:31.042+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-24T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:31.042+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:36:31.043+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:31.043+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=14, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:36:31.043+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:31.052+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-10T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:32.375+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:36:32.499+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:32.577+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:36:32.577+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:33.297+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-10T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:36:33.988+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-22T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:35.419+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:36:35.522+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:35.566+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:36:35.567+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:36.230+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-22T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:36:37.022+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-23T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:38.642+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:36:38.758+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:38.816+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:36:38.816+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:39.386+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-23T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:36:40.130+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-23T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:41.757+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:36:41.844+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:41.893+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:36:41.893+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:42.552+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-23T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:36:43.282+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-24T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:45.025+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:36:45.131+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:45.178+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:36:45.179+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:45.820+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-24T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:36:46.554+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-24T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:47.978+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:36:48.076+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:48.141+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:36:48.142+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:48.885+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-24T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:36:49.576+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:50.759+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:36:50.847+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:50.892+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:36:50.893+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:51.532+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:36:52.481+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:36:54.377+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:36:54.475+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:54.535+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:36:54.535+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:36:55.248+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:36:55.999+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-10T04:10:00+00:00', try_number=18, map_index=-1)[0m
[[34m2024-07-29T17:36:55.999+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-22T04:10:00+00:00', try_number=14, map_index=-1)[0m
[[34m2024-07-29T17:36:55.999+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-23T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:36:56.000+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-23T04:10:00+00:00', try_number=14, map_index=-1)[0m
[[34m2024-07-29T17:36:56.000+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-24T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:36:56.000+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-24T04:10:00+00:00', try_number=14, map_index=-1)[0m
[[34m2024-07-29T17:36:56.000+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:36:56.000+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=14, map_index=-1)[0m
[[34m2024-07-29T17:36:56.026+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-10T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:36:33.376448+00:00, run_end_date=2024-07-29 08:36:33.533612+00:00, run_duration=0.157164, state=success, executor_state=success, try_number=18, max_tries=18, job_id=3034, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:36:31.037418+00:00, queued_by_job_id=3032, pid=306452[0m
[[34m2024-07-29T17:36:56.027+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-22T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:36:36.338766+00:00, run_end_date=2024-07-29 08:36:36.499364+00:00, run_duration=0.160598, state=success, executor_state=success, try_number=14, max_tries=14, job_id=3036, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:36:31.037418+00:00, queued_by_job_id=3032, pid=306473[0m
[[34m2024-07-29T17:36:56.027+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:36:55.351411+00:00, run_end_date=2024-07-29 08:36:55.506621+00:00, run_duration=0.15521, state=success, executor_state=success, try_number=14, max_tries=14, job_id=3047, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:36:31.037418+00:00, queued_by_job_id=3032, pid=306601[0m
[[34m2024-07-29T17:36:56.027+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:36:51.601149+00:00, run_end_date=2024-07-29 08:36:51.795082+00:00, run_duration=0.193933, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3045, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 08:36:31.037418+00:00, queued_by_job_id=3032, pid=306572[0m
[[34m2024-07-29T17:36:56.027+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-24T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:36:48.953077+00:00, run_end_date=2024-07-29 08:36:49.128934+00:00, run_duration=0.175857, state=success, executor_state=success, try_number=14, max_tries=14, job_id=3044, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:36:31.037418+00:00, queued_by_job_id=3032, pid=306559[0m
[[34m2024-07-29T17:36:56.028+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-24T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:36:45.891485+00:00, run_end_date=2024-07-29 08:36:46.060172+00:00, run_duration=0.168687, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3042, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 08:36:31.037418+00:00, queued_by_job_id=3032, pid=306537[0m
[[34m2024-07-29T17:36:56.028+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-23T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:36:42.629776+00:00, run_end_date=2024-07-29 08:36:42.782263+00:00, run_duration=0.152487, state=success, executor_state=success, try_number=14, max_tries=14, job_id=3040, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:36:31.037418+00:00, queued_by_job_id=3032, pid=306517[0m
[[34m2024-07-29T17:36:56.028+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-23T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:36:39.463355+00:00, run_end_date=2024-07-29 08:36:39.625592+00:00, run_duration=0.162237, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3038, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 08:36:31.037418+00:00, queued_by_job_id=3032, pid=306495[0m
[[34m2024-07-29T17:36:56.300+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T17:36:57.476+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T17:36:57.591+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:16:23.138985+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:36:57.591+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-29 08:16:24.076048+00:00, run_end_date=2024-07-29 08:36:57.591363+00:00, run_duration=1233.515315, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=6441f40e731f53180eb8b0797100add2[0m
[[34m2024-07-29T17:36:57.593+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T17:36:58.734+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T17:36:59.911+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T17:37:01.091+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-29T17:37:14.055+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:37:14.055+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-29T17:37:14.055+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:37:14.056+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=22, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:37:14.056+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:37:14.065+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:37:15.285+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:37:15.359+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:37:15.401+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:37:15.402+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:37:15.874+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:37:35.387+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=22, map_index=-1)[0m
[[34m2024-07-29T17:37:35.392+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:37:15.926687+00:00, run_end_date=2024-07-29 08:37:34.905246+00:00, run_duration=18.978559, state=failed, executor_state=success, try_number=22, max_tries=21, job_id=3049, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:37:14.055716+00:00, queued_by_job_id=3032, pid=306726[0m
[[34m2024-07-29T17:37:35.584+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:37:35.584+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-29T17:37:35.584+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-29T17:37:35.584+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:37:35.586+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=22, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:37:35.586+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:37:35.586+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:37:35.586+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:37:35.594+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:37:36.849+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:37:36.936+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:37:37.001+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:37:37.002+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:37:37.688+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:37:57.314+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:37:58.786+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:37:58.906+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:37:58.981+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:37:58.981+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:37:59.614+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:38:00.431+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=22, map_index=-1)[0m
[[34m2024-07-29T17:38:00.432+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:38:00.437+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:37:37.752029+00:00, run_end_date=2024-07-29 08:37:56.737379+00:00, run_duration=18.98535, state=failed, executor_state=success, try_number=22, max_tries=21, job_id=3051, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:37:35.585195+00:00, queued_by_job_id=3032, pid=306866[0m
[[34m2024-07-29T17:38:00.438+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:37:59.676200+00:00, run_end_date=2024-07-29 08:37:59.833725+00:00, run_duration=0.157525, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3054, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 08:37:35.585195+00:00, queued_by_job_id=3032, pid=306970[0m
[[34m2024-07-29T17:38:00.677+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:38:00.677+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T17:38:00.677+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-29T17:38:00.677+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:38:00.679+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=15, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:38:00.679+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:38:00.679+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:38:00.680+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:38:00.689+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:38:02.083+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:38:02.180+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:38:02.226+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:38:02.227+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:38:02.857+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:38:22.232+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:38:23.585+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:38:23.684+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:38:23.739+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:38:23.740+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:38:24.310+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:38:25.053+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=15, map_index=-1)[0m
[[34m2024-07-29T17:38:25.054+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:38:25.065+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:38:24.369966+00:00, run_end_date=2024-07-29 08:38:24.537600+00:00, run_duration=0.167634, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3058, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 08:38:00.678246+00:00, queued_by_job_id=3032, pid=307128[0m
[[34m2024-07-29T17:38:25.065+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:38:02.912674+00:00, run_end_date=2024-07-29 08:38:21.735458+00:00, run_duration=18.822784, state=up_for_retry, executor_state=success, try_number=15, max_tries=14, job_id=3056, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:38:00.678246+00:00, queued_by_job_id=3032, pid=306993[0m
[[34m2024-07-29T17:38:25.497+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:38:25.498+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 15/16 running and queued tasks[0m
[[34m2024-07-29T17:38:25.498+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:38:25.499+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=16, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:38:25.499+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:38:25.511+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:38:26.970+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:38:27.096+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:38:27.173+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:38:27.174+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:38:27.780+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:38:47.865+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=16, map_index=-1)[0m
[[34m2024-07-29T17:38:47.868+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:38:27.842006+00:00, run_end_date=2024-07-29 08:38:47.299041+00:00, run_duration=19.457035, state=failed, executor_state=success, try_number=16, max_tries=14, job_id=3059, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:38:25.498698+00:00, queued_by_job_id=3032, pid=307144[0m
[[34m2024-07-29T17:38:48.122+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-10T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:38:48.123+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 14/16 running and queued tasks[0m
[[34m2024-07-29T17:38:48.123+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 15/16 running and queued tasks[0m
[[34m2024-07-29T17:38:48.123+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-10T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:38:48.125+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-10T04:10:00+00:00', try_number=32, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:38:48.126+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-10T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:38:48.126+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:38:48.126+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:38:48.134+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-10T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:38:49.618+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:38:49.758+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:38:49.824+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:38:49.825+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:38:50.643+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-10T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:39:10.097+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:39:11.420+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:39:11.507+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:39:11.560+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:39:11.561+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:39:12.127+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:39:12.884+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-10T04:10:00+00:00', try_number=32, map_index=-1)[0m
[[34m2024-07-29T17:39:12.884+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:39:12.889+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-10T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:38:50.711848+00:00, run_end_date=2024-07-29 08:39:09.577370+00:00, run_duration=18.865522, state=failed, executor_state=success, try_number=32, max_tries=31, job_id=3061, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:38:48.124538+00:00, queued_by_job_id=3032, pid=307279[0m
[[34m2024-07-29T17:39:12.889+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:39:12.189242+00:00, run_end_date=2024-07-29 08:39:12.343345+00:00, run_duration=0.154103, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3063, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 08:38:48.124538+00:00, queued_by_job_id=3032, pid=307411[0m
[[34m2024-07-29T17:39:13.154+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-10 04:10:00+00:00: scheduled__2024-07-10T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:38:16.698241+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:39:13.155+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-10 04:10:00+00:00, run_id=scheduled__2024-07-10T04:10:00+00:00, run_start_date=2024-07-29 08:38:16.798290+00:00, run_end_date=2024-07-29 08:39:13.154929+00:00, run_duration=56.356639, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-10 04:10:00+00:00, data_interval_end=2024-07-11 04:10:00+00:00, dag_hash=f5ba9f856c7b4703187e7375a16b1a72[0m
[[34m2024-07-29T17:39:13.156+0900[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG movie is at (or above) max_active_runs (18 of 16), not creating any more runs[0m
[[34m2024-07-29T17:39:13.223+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-11T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:39:13.224+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 13/16 running and queued tasks[0m
[[34m2024-07-29T17:39:13.224+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-11T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:39:13.225+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-11T04:10:00+00:00', try_number=29, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:39:13.225+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-11T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:39:13.236+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-11T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:39:14.651+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:39:14.756+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:39:14.812+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:39:14.812+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:39:15.425+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-11T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:39:36.013+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-11T04:10:00+00:00', try_number=29, map_index=-1)[0m
[[34m2024-07-29T17:39:36.017+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-11T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:39:15.486192+00:00, run_end_date=2024-07-29 08:39:35.483814+00:00, run_duration=19.997622, state=failed, executor_state=success, try_number=29, max_tries=28, job_id=3064, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:39:13.224725+00:00, queued_by_job_id=3032, pid=307425[0m
[[34m2024-07-29T17:39:36.200+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-11 04:10:00+00:00: scheduled__2024-07-11T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:38:16.698299+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:39:36.200+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-11 04:10:00+00:00, run_id=scheduled__2024-07-11T04:10:00+00:00, run_start_date=2024-07-29 08:38:16.798439+00:00, run_end_date=2024-07-29 08:39:36.200848+00:00, run_duration=79.402409, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-11 04:10:00+00:00, data_interval_end=2024-07-12 04:10:00+00:00, dag_hash=f5ba9f856c7b4703187e7375a16b1a72[0m
[[34m2024-07-29T17:39:36.203+0900[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG movie is at (or above) max_active_runs (17 of 16), not creating any more runs[0m
[[34m2024-07-29T17:39:36.206+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-28 04:10:00+00:00: scheduled__2024-07-28T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:16:23.139019+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:39:36.207+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-28 04:10:00+00:00, run_id=scheduled__2024-07-28T04:10:00+00:00, run_start_date=2024-07-29 08:36:49.623862+00:00, run_end_date=2024-07-29 08:39:36.206958+00:00, run_duration=166.583096, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-28 04:10:00+00:00, data_interval_end=2024-07-29 04:10:00+00:00, dag_hash=f5ba9f856c7b4703187e7375a16b1a72[0m
[[34m2024-07-29T17:39:36.209+0900[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG movie is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
[[34m2024-07-29T17:39:36.276+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-12T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-24T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:39:36.277+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 12/16 running and queued tasks[0m
[[34m2024-07-29T17:39:36.277+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 13/16 running and queued tasks[0m
[[34m2024-07-29T17:39:36.277+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-12T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-24T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:39:36.279+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-12T04:10:00+00:00', try_number=29, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:39:36.280+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-12T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:39:36.280+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-24T04:10:00+00:00', try_number=26, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-29T17:39:36.281+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-24T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:39:36.292+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-12T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:39:37.823+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:39:37.948+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:39:38.005+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:39:38.005+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:39:38.678+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-12T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:39:58.926+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-24T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:40:00.571+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:40:00.701+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:40:00.753+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:40:00.753+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:40:01.421+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-24T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:40:22.148+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-12T04:10:00+00:00', try_number=29, map_index=-1)[0m
[[34m2024-07-29T17:40:22.148+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-24T04:10:00+00:00', try_number=26, map_index=-1)[0m
[[34m2024-07-29T17:40:22.157+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-12T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:39:38.755047+00:00, run_end_date=2024-07-29 08:39:58.361940+00:00, run_duration=19.606893, state=failed, executor_state=success, try_number=29, max_tries=28, job_id=3066, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:39:36.277945+00:00, queued_by_job_id=3032, pid=307564[0m
[[34m2024-07-29T17:40:22.157+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-24T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:40:01.496772+00:00, run_end_date=2024-07-29 08:40:21.653967+00:00, run_duration=20.157195, state=up_for_retry, executor_state=success, try_number=26, max_tries=26, job_id=3068, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:39:36.277945+00:00, queued_by_job_id=3032, pid=307698[0m
[[34m2024-07-29T17:40:22.362+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-12 04:10:00+00:00: scheduled__2024-07-12T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:38:16.698316+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:40:22.362+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-12 04:10:00+00:00, run_id=scheduled__2024-07-12T04:10:00+00:00, run_start_date=2024-07-29 08:38:16.798479+00:00, run_end_date=2024-07-29 08:40:22.362665+00:00, run_duration=125.564186, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-12 04:10:00+00:00, data_interval_end=2024-07-13 04:10:00+00:00, dag_hash=f5ba9f856c7b4703187e7375a16b1a72[0m
[[34m2024-07-29T17:40:22.367+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:40:22.425+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-13T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-14T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:40:22.426+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 10/16 running and queued tasks[0m
[[34m2024-07-29T17:40:22.426+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 11/16 running and queued tasks[0m
[[34m2024-07-29T17:40:22.426+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 12/16 running and queued tasks[0m
[[34m2024-07-29T17:40:22.426+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 13/16 running and queued tasks[0m
[[34m2024-07-29T17:40:22.426+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-13T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-14T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:40:22.428+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-13T04:10:00+00:00', try_number=27, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:40:22.428+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-13T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:40:22.428+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-14T04:10:00+00:00', try_number=29, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:40:22.429+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-14T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:40:22.429+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=26, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-29T17:40:22.429+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:40:22.429+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=23, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-29T17:40:22.429+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:40:22.439+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-13T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:40:23.963+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:40:24.084+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:40:24.137+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:40:24.138+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:40:24.742+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-13T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:40:44.535+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-14T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:40:46.017+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:40:46.122+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:40:46.171+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:40:46.171+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:40:46.760+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-14T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:41:06.464+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:07.876+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:41:08.003+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:41:08.056+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:41:08.057+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:41:08.828+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:41:28.347+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:29.839+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:41:29.965+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:41:30.023+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:41:30.024+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:41:30.743+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:41:52.199+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-13T04:10:00+00:00', try_number=27, map_index=-1)[0m
[[34m2024-07-29T17:41:52.199+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-14T04:10:00+00:00', try_number=29, map_index=-1)[0m
[[34m2024-07-29T17:41:52.199+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=26, map_index=-1)[0m
[[34m2024-07-29T17:41:52.200+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=23, map_index=-1)[0m
[[34m2024-07-29T17:41:52.211+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-13T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:40:24.804933+00:00, run_end_date=2024-07-29 08:40:43.991025+00:00, run_duration=19.186092, state=failed, executor_state=success, try_number=27, max_tries=26, job_id=3070, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:40:22.427261+00:00, queued_by_job_id=3032, pid=307833[0m
[[34m2024-07-29T17:41:52.212+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-14T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:40:46.819253+00:00, run_end_date=2024-07-29 08:41:05.964653+00:00, run_duration=19.1454, state=failed, executor_state=success, try_number=29, max_tries=28, job_id=3072, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:40:22.427261+00:00, queued_by_job_id=3032, pid=307967[0m
[[34m2024-07-29T17:41:52.212+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:41:08.927302+00:00, run_end_date=2024-07-29 08:41:27.828439+00:00, run_duration=18.901137, state=up_for_retry, executor_state=success, try_number=26, max_tries=26, job_id=3074, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:40:22.427261+00:00, queued_by_job_id=3032, pid=308102[0m
[[34m2024-07-29T17:41:52.212+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:41:30.819507+00:00, run_end_date=2024-07-29 08:41:51.680051+00:00, run_duration=20.860544, state=up_for_retry, executor_state=success, try_number=23, max_tries=23, job_id=3076, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:40:22.427261+00:00, queued_by_job_id=3032, pid=308236[0m
[[34m2024-07-29T17:41:52.224+0900[0m] {[34mmanager.py:[0m285} ERROR[0m - DagFileProcessorManager (PID=306422) last sent a heartbeat 89.91 seconds ago! Restarting it[0m
[[34m2024-07-29T17:41:52.226+0900[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 306422. PIDs of all processes in the group: [306422][0m
[[34m2024-07-29T17:41:52.226+0900[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 306422[0m
[[34m2024-07-29T17:41:52.400+0900[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Process psutil.Process(pid=306422, status='terminated', exitcode=0, started='17:36:29') (306422) terminated with exit code 0[0m
[[34m2024-07-29T17:41:52.403+0900[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 308364[0m
[[34m2024-07-29T17:41:52.409+0900[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[2024-07-29T17:41:52.435+0900] {manager.py:393} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-07-29T17:41:52.455+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T17:41:52.457+0900[0m] {[34mscheduler_job_runner.py:[0m1621} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[[34m2024-07-29T17:41:52.467+0900[0m] {[34mscheduler_job_runner.py:[0m1657} INFO[0m - Reset the following 6 orphaned TaskInstances:
	<TaskInstance: movie.get.data scheduled__2024-07-20T04:10:00+00:00 [queued]>
	<TaskInstance: movie.get.data scheduled__2024-07-21T04:10:00+00:00 [queued]>
	<TaskInstance: movie.get.data scheduled__2024-07-22T04:10:00+00:00 [queued]>
	<TaskInstance: movie.get.data scheduled__2024-07-23T04:10:00+00:00 [queued]>
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [queued]>
	<TaskInstance: movie.get.data scheduled__2024-07-19T04:10:00+00:00 [running]>[0m
[[34m2024-07-29T17:41:52.806+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-13 04:10:00+00:00: scheduled__2024-07-13T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:38:16.698331+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:41:52.807+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-13 04:10:00+00:00, run_id=scheduled__2024-07-13T04:10:00+00:00, run_start_date=2024-07-29 08:38:16.798515+00:00, run_end_date=2024-07-29 08:41:52.807238+00:00, run_duration=216.008723, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-13 04:10:00+00:00, data_interval_end=2024-07-14 04:10:00+00:00, dag_hash=6441f40e731f53180eb8b0797100add2[0m
[[34m2024-07-29T17:41:52.810+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:41:52.824+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-14 04:10:00+00:00: scheduled__2024-07-14T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:38:16.698345+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:41:52.824+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-14 04:10:00+00:00, run_id=scheduled__2024-07-14T04:10:00+00:00, run_start_date=2024-07-29 08:38:16.798576+00:00, run_end_date=2024-07-29 08:41:52.824750+00:00, run_duration=216.026174, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-14 04:10:00+00:00, data_interval_end=2024-07-15 04:10:00+00:00, dag_hash=6441f40e731f53180eb8b0797100add2[0m
[[34m2024-07-29T17:41:52.828+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:41:52.914+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 12 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-15T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-16T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-17T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-18T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-19T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-24T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-20T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-21T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-22T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-23T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:41:52.915+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.915+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.915+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.915+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.915+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.915+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.916+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.916+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.916+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 8/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.916+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 9/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.916+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 10/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.916+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 11/16 running and queued tasks[0m
[[34m2024-07-29T17:41:52.917+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-15T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-16T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-17T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-18T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-19T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-24T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-20T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-21T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-22T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-23T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:41:52.919+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-15T04:10:00+00:00', try_number=27, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:41:52.920+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-15T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.920+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-16T04:10:00+00:00', try_number=27, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:41:52.920+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-16T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.920+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-17T04:10:00+00:00', try_number=27, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:41:52.920+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-17T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.921+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-18T04:10:00+00:00', try_number=28, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:41:52.921+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-18T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.921+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-19T04:10:00+00:00', try_number=27, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:41:52.921+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-19T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.921+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-24T04:10:00+00:00', try_number=27, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:41:52.921+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-24T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.922+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=27, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T17:41:52.922+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.922+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-20T04:10:00+00:00', try_number=26, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-29T17:41:52.922+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-20T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.922+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-21T04:10:00+00:00', try_number=26, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-29T17:41:52.922+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-21T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.922+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-22T04:10:00+00:00', try_number=26, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-29T17:41:52.923+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-22T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.923+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-23T04:10:00+00:00', try_number=26, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-29T17:41:52.923+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-23T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.923+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=23, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-29T17:41:52.923+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:52.933+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-15T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:41:54.565+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:41:54.722+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:41:54.788+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:41:54.789+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:41:55.410+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-15T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:42:14.909+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-16T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:42:16.263+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:42:16.379+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:42:16.429+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:42:16.429+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:42:17.071+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-16T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:42:37.505+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-17T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:42:38.919+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:42:39.046+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:42:39.087+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:42:39.087+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:42:39.660+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-17T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:43:00.142+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-18T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:43:01.738+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:43:01.859+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:43:01.922+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:43:01.923+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:43:02.619+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-18T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:43:24.920+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-19T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:43:26.408+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:43:26.522+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:43:26.573+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:43:26.574+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:43:27.303+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-19T04:10:00+00:00 [failed]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:43:27.870+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-24T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:43:29.362+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:43:29.470+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:43:29.523+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:43:29.524+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:43:30.146+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-24T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:43:50.982+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:43:52.314+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:43:52.412+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:43:52.458+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:43:52.458+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:43:53.199+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:44:04.014+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-20T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:44:05.460+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:44:05.568+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:44:05.632+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:44:05.632+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:44:06.215+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-20T04:10:00+00:00 [running]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:44:06.704+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-21T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:44:07.971+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:44:08.087+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:44:08.139+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:44:08.140+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:44:08.761+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-21T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:44:33.849+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-22T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:44:35.278+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:44:35.390+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:44:35.443+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:44:35.444+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:44:36.143+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-22T04:10:00+00:00 [running]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:44:36.805+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-23T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:44:38.332+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:44:38.466+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:44:38.529+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:44:38.530+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:44:39.205+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-23T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:45:02.142+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:45:03.371+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:45:03.473+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:45:03.521+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:45:03.521+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:45:04.246+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [up_for_retry]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:45:24.091+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-15T04:10:00+00:00', try_number=27, map_index=-1)[0m
[[34m2024-07-29T17:45:24.092+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-16T04:10:00+00:00', try_number=27, map_index=-1)[0m
[[34m2024-07-29T17:45:24.092+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-17T04:10:00+00:00', try_number=27, map_index=-1)[0m
[[34m2024-07-29T17:45:24.092+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-18T04:10:00+00:00', try_number=28, map_index=-1)[0m
[[34m2024-07-29T17:45:24.092+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-19T04:10:00+00:00', try_number=27, map_index=-1)[0m
[[34m2024-07-29T17:45:24.092+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-24T04:10:00+00:00', try_number=27, map_index=-1)[0m
[[34m2024-07-29T17:45:24.092+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=27, map_index=-1)[0m
[[34m2024-07-29T17:45:24.093+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-20T04:10:00+00:00', try_number=26, map_index=-1)[0m
[[34m2024-07-29T17:45:24.093+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-21T04:10:00+00:00', try_number=26, map_index=-1)[0m
[[34m2024-07-29T17:45:24.093+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-22T04:10:00+00:00', try_number=26, map_index=-1)[0m
[[34m2024-07-29T17:45:24.093+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-23T04:10:00+00:00', try_number=26, map_index=-1)[0m
[[34m2024-07-29T17:45:24.093+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=23, map_index=-1)[0m
[[34m2024-07-29T17:45:24.099+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-15T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:41:55.562900+00:00, run_end_date=2024-07-29 08:42:14.372178+00:00, run_duration=18.809278, state=failed, executor_state=success, try_number=27, max_tries=26, job_id=3078, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:41:52.917438+00:00, queued_by_job_id=3032, pid=308375[0m
[[34m2024-07-29T17:45:24.099+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-16T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:42:17.150356+00:00, run_end_date=2024-07-29 08:42:36.933030+00:00, run_duration=19.782674, state=failed, executor_state=success, try_number=27, max_tries=26, job_id=3080, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:41:52.917438+00:00, queued_by_job_id=3032, pid=308501[0m
[[34m2024-07-29T17:45:24.099+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-17T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:42:39.756577+00:00, run_end_date=2024-07-29 08:42:59.506800+00:00, run_duration=19.750223, state=failed, executor_state=success, try_number=27, max_tries=26, job_id=3082, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:41:52.917438+00:00, queued_by_job_id=3032, pid=308635[0m
[[34m2024-07-29T17:45:24.100+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-18T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:43:02.691986+00:00, run_end_date=2024-07-29 08:43:24.344929+00:00, run_duration=21.652943, state=failed, executor_state=success, try_number=28, max_tries=27, job_id=3084, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:41:52.917438+00:00, queued_by_job_id=3032, pid=308769[0m
[[34m2024-07-29T17:45:24.100+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-19T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:41:41.815720+00:00, run_end_date=2024-07-29 08:42:02.327016+00:00, run_duration=20.511296, state=failed, executor_state=success, try_number=27, max_tries=26, job_id=3077, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:41:52.917438+00:00, queued_by_job_id=3032, pid=308306[0m
[[34m2024-07-29T17:45:24.100+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-20T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:43:59.687334+00:00, run_end_date=2024-07-29 08:44:21.576654+00:00, run_duration=21.88932, state=failed, executor_state=success, try_number=26, max_tries=26, job_id=3090, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:43:57.341431+00:00, queued_by_job_id=3004, pid=309113[0m
[[34m2024-07-29T17:45:24.100+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-21T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:44:08.844126+00:00, run_end_date=2024-07-29 08:44:33.263475+00:00, run_duration=24.419349, state=failed, executor_state=success, try_number=26, max_tries=26, job_id=3092, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:43:57.341431+00:00, queued_by_job_id=3004, pid=309182[0m
[[34m2024-07-29T17:45:24.100+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-22T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:44:28.018117+00:00, run_end_date=2024-07-29 08:44:49.373884+00:00, run_duration=21.355767, state=failed, executor_state=success, try_number=26, max_tries=26, job_id=3094, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:43:57.341431+00:00, queued_by_job_id=3004, pid=309258[0m
[[34m2024-07-29T17:45:24.100+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-23T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:44:39.279301+00:00, run_end_date=2024-07-29 08:45:01.645468+00:00, run_duration=22.366167, state=failed, executor_state=success, try_number=26, max_tries=26, job_id=3096, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:43:57.341431+00:00, queued_by_job_id=3004, pid=309334[0m
[[34m2024-07-29T17:45:24.100+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-24T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:43:30.222882+00:00, run_end_date=2024-07-29 08:43:50.453823+00:00, run_duration=20.230941, state=failed, executor_state=success, try_number=27, max_tries=26, job_id=3087, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:41:52.917438+00:00, queued_by_job_id=3032, pid=308912[0m
[[34m2024-07-29T17:45:24.101+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:43:53.283610+00:00, run_end_date=2024-07-29 08:44:03.556308+00:00, run_duration=10.272698, state=failed, executor_state=success, try_number=27, max_tries=26, job_id=3089, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:43:57.341431+00:00, queued_by_job_id=3004, pid=309046[0m
[[34m2024-07-29T17:45:24.101+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:45:04.326868+00:00, run_end_date=2024-07-29 08:45:23.630579+00:00, run_duration=19.303711, state=failed, executor_state=success, try_number=23, max_tries=23, job_id=3100, pool=default_pool, queue=default, priority_weight=8, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 08:41:52.917438+00:00, queued_by_job_id=3032, pid=309482[0m
[[34m2024-07-29T17:45:24.112+0900[0m] {[34mmanager.py:[0m285} ERROR[0m - DagFileProcessorManager (PID=308364) last sent a heartbeat 211.38 seconds ago! Restarting it[0m
[[34m2024-07-29T17:45:24.113+0900[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 308364. PIDs of all processes in the group: [308364][0m
[[34m2024-07-29T17:45:24.114+0900[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 308364[0m
[[34m2024-07-29T17:45:24.247+0900[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Process psutil.Process(pid=308364, status='terminated', exitcode=0, started='17:41:51') (308364) terminated with exit code 0[0m
[[34m2024-07-29T17:45:24.250+0900[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 309558[0m
[[34m2024-07-29T17:45:24.255+0900[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[2024-07-29T17:45:24.274+0900] {manager.py:393} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-07-29T17:45:24.556+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:16:23.139008+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:45:24.557+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-29 08:36:49.623846+00:00, run_end_date=2024-07-29 08:45:24.557069+00:00, run_duration=514.933223, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=6441f40e731f53180eb8b0797100add2[0m
[[34m2024-07-29T17:45:24.559+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T17:45:25.701+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-29T17:46:52.608+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T17:51:52.748+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T17:53:33.719+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-10T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.729+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-11T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.736+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-12T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.744+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-13T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.751+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-14T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.759+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-15T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.766+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-16T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.775+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-17T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.783+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-18T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.790+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-19T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.798+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-20T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.805+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-21T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.813+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-22T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.820+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-23T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.828+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-24T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:33.836+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-25T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:35.138+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:53:35.138+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 16/16 running and queued tasks[0m
[[34m2024-07-29T17:53:35.138+0900[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG movie is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-29T17:53:36.335+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:53:36.335+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 15/16 running and queued tasks[0m
[[34m2024-07-29T17:53:36.335+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:53:36.336+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=15, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:53:36.336+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:36.348+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:37.684+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:53:37.798+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:37.845+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:53:37.846+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:38.415+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:53:39.036+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=15, map_index=-1)[0m
[[34m2024-07-29T17:53:39.039+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:53:38.465451+00:00, run_end_date=2024-07-29 08:53:38.586116+00:00, run_duration=0.120665, state=success, executor_state=success, try_number=15, max_tries=15, job_id=3102, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:53:36.336043+00:00, queued_by_job_id=3032, pid=310807[0m
[[34m2024-07-29T17:53:39.271+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:53:39.271+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 14/16 running and queued tasks[0m
[[34m2024-07-29T17:53:39.271+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:53:39.274+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:53:39.274+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:39.282+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:40.598+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:53:40.692+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:40.740+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:53:40.740+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:41.374+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:53:42.104+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-29T17:53:42.107+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:53:41.432394+00:00, run_end_date=2024-07-29 08:53:41.589046+00:00, run_duration=0.156652, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=3104, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:53:39.271974+00:00, queued_by_job_id=3032, pid=310828[0m
[[34m2024-07-29T17:53:42.239+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-10 04:10:00+00:00: scheduled__2024-07-10T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423048+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:53:42.239+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-10 04:10:00+00:00, run_id=scheduled__2024-07-10T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.703888+00:00, run_end_date=2024-07-29 08:53:42.239903+00:00, run_duration=8.536015, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-10 04:10:00+00:00, data_interval_end=2024-07-11 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:53:42.241+0900[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG movie is at (or above) max_active_runs (18 of 16), not creating any more runs[0m
[[34m2024-07-29T17:53:42.284+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423402+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:53:42.284+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704168+00:00, run_end_date=2024-07-29 08:53:42.284725+00:00, run_duration=8.580557, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:53:42.287+0900[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG movie is at (or above) max_active_runs (17 of 16), not creating any more runs[0m
[[34m2024-07-29T17:53:43.542+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-26T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:43.552+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-27T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:43.557+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-11 04:10:00+00:00: scheduled__2024-07-11T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423112+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:53:43.558+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-11 04:10:00+00:00, run_id=scheduled__2024-07-11T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.703978+00:00, run_end_date=2024-07-29 08:53:43.558076+00:00, run_duration=9.854098, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-11 04:10:00+00:00, data_interval_end=2024-07-12 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:53:43.559+0900[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG movie is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
[[34m2024-07-29T17:53:43.928+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.a scheduled__2024-07-28T04:10:00+00:00 [upstream_failed]>. Marking it as removed.[0m
[[34m2024-07-29T17:53:44.015+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:53:44.015+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 13/16 running and queued tasks[0m
[[34m2024-07-29T17:53:44.015+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 14/16 running and queued tasks[0m
[[34m2024-07-29T17:53:44.015+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 15/16 running and queued tasks[0m
[[34m2024-07-29T17:53:44.015+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 16/16 running and queued tasks[0m
[[34m2024-07-29T17:53:44.015+0900[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]> since the number of tasks running or queued from DAG movie is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-29T17:53:44.015+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:53:44.017+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:53:44.017+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:44.017+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:53:44.017+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:44.018+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=14, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:53:44.018+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:44.027+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:45.391+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:53:45.481+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:45.533+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:53:45.533+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:46.132+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:53:46.808+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:48.095+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:53:48.191+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:48.236+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:53:48.237+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:48.923+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:53:49.637+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:50.956+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:53:51.052+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:51.130+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:53:51.131+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:51.745+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:53:52.405+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:53:52.405+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:53:52.406+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=14, map_index=-1)[0m
[[34m2024-07-29T17:53:52.412+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:53:48.990597+00:00, run_end_date=2024-07-29 08:53:49.141509+00:00, run_duration=0.150912, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=3109, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:53:44.016274+00:00, queued_by_job_id=3032, pid=310882[0m
[[34m2024-07-29T17:53:52.413+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:53:46.186337+00:00, run_end_date=2024-07-29 08:53:46.314317+00:00, run_duration=0.12798, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=3107, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:53:44.016274+00:00, queued_by_job_id=3032, pid=310860[0m
[[34m2024-07-29T17:53:52.413+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:53:51.803927+00:00, run_end_date=2024-07-29 08:53:51.919490+00:00, run_duration=0.115563, state=success, executor_state=success, try_number=14, max_tries=14, job_id=3111, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:53:44.016274+00:00, queued_by_job_id=3032, pid=310902[0m
[[34m2024-07-29T17:53:52.976+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:53:52.977+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 9/16 running and queued tasks[0m
[[34m2024-07-29T17:53:52.977+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 10/16 running and queued tasks[0m
[[34m2024-07-29T17:53:52.977+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 11/16 running and queued tasks[0m
[[34m2024-07-29T17:53:52.978+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 12/16 running and queued tasks[0m
[[34m2024-07-29T17:53:52.978+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 13/16 running and queued tasks[0m
[[34m2024-07-29T17:53:52.978+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:53:52.982+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:53:52.983+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:52.983+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:53:52.984+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:52.984+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:53:52.984+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:52.985+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=14, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:53:52.985+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:52.985+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=7, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:53:52.985+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:52.993+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:54.718+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:53:54.810+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:54.858+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:53:54.858+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:55.431+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:53:56.141+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:53:57.698+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:53:57.806+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:57.856+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:53:57.857+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:53:58.426+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:53:59.119+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:54:00.720+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:54:00.814+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:54:00.860+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:54:00.861+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:54:01.472+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:54:02.150+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:54:03.574+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:54:03.665+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:54:03.718+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:54:03.719+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:54:04.395+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:54:05.075+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:54:06.526+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:54:06.646+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:54:06.693+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:54:06.694+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:54:07.300+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:54:08.030+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-29T17:54:08.031+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-29T17:54:08.031+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:54:08.031+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=14, map_index=-1)[0m
[[34m2024-07-29T17:54:08.031+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=7, map_index=-1)[0m
[[34m2024-07-29T17:54:08.040+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:53:58.494402+00:00, run_end_date=2024-07-29 08:53:58.616856+00:00, run_duration=0.122454, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=3115, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:53:52.980020+00:00, queued_by_job_id=3032, pid=310944[0m
[[34m2024-07-29T17:54:08.041+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:54:04.472833+00:00, run_end_date=2024-07-29 08:54:04.612240+00:00, run_duration=0.139407, state=success, executor_state=success, try_number=14, max_tries=14, job_id=3119, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:53:52.980020+00:00, queued_by_job_id=3032, pid=310986[0m
[[34m2024-07-29T17:54:08.041+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:53:55.493384+00:00, run_end_date=2024-07-29 08:53:55.653952+00:00, run_duration=0.160568, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=3113, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:53:52.980020+00:00, queued_by_job_id=3032, pid=310924[0m
[[34m2024-07-29T17:54:08.041+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:54:01.529164+00:00, run_end_date=2024-07-29 08:54:01.667590+00:00, run_duration=0.138426, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=3117, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:53:52.980020+00:00, queued_by_job_id=3032, pid=310966[0m
[[34m2024-07-29T17:54:08.042+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:54:07.365202+00:00, run_end_date=2024-07-29 08:54:07.496011+00:00, run_duration=0.130809, state=success, executor_state=success, try_number=7, max_tries=7, job_id=3121, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:53:52.980020+00:00, queued_by_job_id=3032, pid=311006[0m
[[34m2024-07-29T17:54:08.316+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-12 04:10:00+00:00: scheduled__2024-07-12T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423132+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:08.316+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-12 04:10:00+00:00, run_id=scheduled__2024-07-12T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.703995+00:00, run_end_date=2024-07-29 08:54:08.316672+00:00, run_duration=34.612677, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-12 04:10:00+00:00, data_interval_end=2024-07-13 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:08.319+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:08.330+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423421+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:08.330+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-29 08:53:43.526336+00:00, run_end_date=2024-07-29 08:54:08.330869+00:00, run_duration=24.804533, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:08.334+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T17:54:08.342+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-13 04:10:00+00:00: scheduled__2024-07-13T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423151+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:08.343+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-13 04:10:00+00:00, run_id=scheduled__2024-07-13T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704009+00:00, run_end_date=2024-07-29 08:54:08.343024+00:00, run_duration=34.639015, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-13 04:10:00+00:00, data_interval_end=2024-07-14 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:08.345+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:08.348+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-14 04:10:00+00:00: scheduled__2024-07-14T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423174+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:08.349+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-14 04:10:00+00:00, run_id=scheduled__2024-07-14T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704030+00:00, run_end_date=2024-07-29 08:54:08.349054+00:00, run_duration=34.645024, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-14 04:10:00+00:00, data_interval_end=2024-07-15 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:08.352+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:08.356+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-15 04:10:00+00:00: scheduled__2024-07-15T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423199+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:08.357+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-15 04:10:00+00:00, run_id=scheduled__2024-07-15T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704044+00:00, run_end_date=2024-07-29 08:54:08.357086+00:00, run_duration=34.653042, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-15 04:10:00+00:00, data_interval_end=2024-07-16 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:08.360+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:08.411+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:54:08.411+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-29T17:54:08.411+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:54:08.412+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:54:08.412+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:54:08.421+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:54:09.834+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:54:09.943+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:54:09.991+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:54:09.991+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:54:10.613+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:54:11.330+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-29T17:54:11.333+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:54:10.689598+00:00, run_end_date=2024-07-29 08:54:10.848797+00:00, run_duration=0.159199, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=3124, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:54:08.411929+00:00, queued_by_job_id=3032, pid=311028[0m
[[34m2024-07-29T17:54:11.462+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T17:54:11.480+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-28 04:10:00+00:00: scheduled__2024-07-28T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423458+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:11.481+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-28 04:10:00+00:00, run_id=scheduled__2024-07-28T04:10:00+00:00, run_start_date=2024-07-29 08:53:43.910397+00:00, run_end_date=2024-07-29 08:54:11.481237+00:00, run_duration=27.57084, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-28 04:10:00+00:00, data_interval_end=2024-07-29 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:11.483+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-29T17:54:11.486+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423439+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:11.486+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-29 08:53:43.526363+00:00, run_end_date=2024-07-29 08:54:11.486671+00:00, run_duration=27.960308, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:11.490+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T17:54:11.495+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-16 04:10:00+00:00: scheduled__2024-07-16T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423220+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:11.495+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-16 04:10:00+00:00, run_id=scheduled__2024-07-16T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704057+00:00, run_end_date=2024-07-29 08:54:11.495665+00:00, run_duration=37.791608, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-16 04:10:00+00:00, data_interval_end=2024-07-17 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:11.500+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:11.504+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-17 04:10:00+00:00: scheduled__2024-07-17T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423244+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:11.505+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-17 04:10:00+00:00, run_id=scheduled__2024-07-17T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704069+00:00, run_end_date=2024-07-29 08:54:11.505234+00:00, run_duration=37.801165, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-17 04:10:00+00:00, data_interval_end=2024-07-18 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:11.510+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:11.514+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-18 04:10:00+00:00: scheduled__2024-07-18T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423265+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:11.515+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-18 04:10:00+00:00, run_id=scheduled__2024-07-18T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704081+00:00, run_end_date=2024-07-29 08:54:11.515452+00:00, run_duration=37.811371, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-18 04:10:00+00:00, data_interval_end=2024-07-19 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:11.519+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:11.524+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-19 04:10:00+00:00: scheduled__2024-07-19T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423284+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:11.525+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-19 04:10:00+00:00, run_id=scheduled__2024-07-19T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704094+00:00, run_end_date=2024-07-29 08:54:11.525337+00:00, run_duration=37.821243, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-19 04:10:00+00:00, data_interval_end=2024-07-20 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:11.530+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:11.535+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-20 04:10:00+00:00: scheduled__2024-07-20T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423304+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:11.535+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-20 04:10:00+00:00, run_id=scheduled__2024-07-20T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704106+00:00, run_end_date=2024-07-29 08:54:11.535601+00:00, run_duration=37.831495, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-20 04:10:00+00:00, data_interval_end=2024-07-21 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:11.540+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:12.713+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T17:54:12.734+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-21 04:10:00+00:00: scheduled__2024-07-21T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423324+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:12.734+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-21 04:10:00+00:00, run_id=scheduled__2024-07-21T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704118+00:00, run_end_date=2024-07-29 08:54:12.734424+00:00, run_duration=39.030306, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-21 04:10:00+00:00, data_interval_end=2024-07-22 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:12.737+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:13.187+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T17:54:14.385+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T17:54:15.551+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T17:54:15.569+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-22 04:10:00+00:00: scheduled__2024-07-22T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423345+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:15.570+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-22 04:10:00+00:00, run_id=scheduled__2024-07-22T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704130+00:00, run_end_date=2024-07-29 08:54:15.570235+00:00, run_duration=41.866105, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-22 04:10:00+00:00, data_interval_end=2024-07-23 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:15.572+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:16.721+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T17:54:17.883+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T17:54:17.904+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-23 04:10:00+00:00: scheduled__2024-07-23T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:53:33.423364+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:17.904+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-23 04:10:00+00:00, run_id=scheduled__2024-07-23T04:10:00+00:00, run_start_date=2024-07-29 08:53:33.704142+00:00, run_end_date=2024-07-29 08:54:17.904325+00:00, run_duration=44.200183, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-23 04:10:00+00:00, data_interval_end=2024-07-24 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:54:17.906+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:18.191+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T17:54:18.487+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T17:54:19.666+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T17:54:20.809+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.505+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-10 04:10:00+00:00: scheduled__2024-07-10T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200883+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.505+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-10 04:10:00+00:00, run_id=scheduled__2024-07-10T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340317+00:00, run_end_date=2024-07-29 08:54:40.505334+00:00, run_duration=0.165017, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-10 04:10:00+00:00, data_interval_end=2024-07-11 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.507+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.512+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-11 04:10:00+00:00: scheduled__2024-07-11T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200910+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.513+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-11 04:10:00+00:00, run_id=scheduled__2024-07-11T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340348+00:00, run_end_date=2024-07-29 08:54:40.513000+00:00, run_duration=0.172652, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-11 04:10:00+00:00, data_interval_end=2024-07-12 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.515+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.522+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-12 04:10:00+00:00: scheduled__2024-07-12T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200921+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.522+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-12 04:10:00+00:00, run_id=scheduled__2024-07-12T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340362+00:00, run_end_date=2024-07-29 08:54:40.522504+00:00, run_duration=0.182142, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-12 04:10:00+00:00, data_interval_end=2024-07-13 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.524+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.530+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-13 04:10:00+00:00: scheduled__2024-07-13T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200931+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.530+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-13 04:10:00+00:00, run_id=scheduled__2024-07-13T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340374+00:00, run_end_date=2024-07-29 08:54:40.530584+00:00, run_duration=0.19021, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-13 04:10:00+00:00, data_interval_end=2024-07-14 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.533+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.540+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-14 04:10:00+00:00: scheduled__2024-07-14T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200941+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.540+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-14 04:10:00+00:00, run_id=scheduled__2024-07-14T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340385+00:00, run_end_date=2024-07-29 08:54:40.540815+00:00, run_duration=0.20043, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-14 04:10:00+00:00, data_interval_end=2024-07-15 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.543+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.549+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-15 04:10:00+00:00: scheduled__2024-07-15T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200951+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.549+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-15 04:10:00+00:00, run_id=scheduled__2024-07-15T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340396+00:00, run_end_date=2024-07-29 08:54:40.549684+00:00, run_duration=0.209288, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-15 04:10:00+00:00, data_interval_end=2024-07-16 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.553+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.559+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-16 04:10:00+00:00: scheduled__2024-07-16T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200961+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.560+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-16 04:10:00+00:00, run_id=scheduled__2024-07-16T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340408+00:00, run_end_date=2024-07-29 08:54:40.560095+00:00, run_duration=0.219687, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-16 04:10:00+00:00, data_interval_end=2024-07-17 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.562+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.569+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-17 04:10:00+00:00: scheduled__2024-07-17T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200972+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.569+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-17 04:10:00+00:00, run_id=scheduled__2024-07-17T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340419+00:00, run_end_date=2024-07-29 08:54:40.569537+00:00, run_duration=0.229118, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-17 04:10:00+00:00, data_interval_end=2024-07-18 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.571+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.577+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-18 04:10:00+00:00: scheduled__2024-07-18T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200982+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.577+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-18 04:10:00+00:00, run_id=scheduled__2024-07-18T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340429+00:00, run_end_date=2024-07-29 08:54:40.577549+00:00, run_duration=0.23712, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-18 04:10:00+00:00, data_interval_end=2024-07-19 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.579+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.585+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-19 04:10:00+00:00: scheduled__2024-07-19T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.200992+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.585+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-19 04:10:00+00:00, run_id=scheduled__2024-07-19T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340478+00:00, run_end_date=2024-07-29 08:54:40.585851+00:00, run_duration=0.245373, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-19 04:10:00+00:00, data_interval_end=2024-07-20 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.587+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.593+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-20 04:10:00+00:00: scheduled__2024-07-20T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.201002+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.593+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-20 04:10:00+00:00, run_id=scheduled__2024-07-20T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340502+00:00, run_end_date=2024-07-29 08:54:40.593495+00:00, run_duration=0.252993, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-20 04:10:00+00:00, data_interval_end=2024-07-21 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.595+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.600+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-21 04:10:00+00:00: scheduled__2024-07-21T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.201012+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.600+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-21 04:10:00+00:00, run_id=scheduled__2024-07-21T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340523+00:00, run_end_date=2024-07-29 08:54:40.600589+00:00, run_duration=0.260066, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-21 04:10:00+00:00, data_interval_end=2024-07-22 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.603+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.608+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-22 04:10:00+00:00: scheduled__2024-07-22T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.201022+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.608+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-22 04:10:00+00:00, run_id=scheduled__2024-07-22T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340545+00:00, run_end_date=2024-07-29 08:54:40.608611+00:00, run_duration=0.268066, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-22 04:10:00+00:00, data_interval_end=2024-07-23 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.610+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.616+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-23 04:10:00+00:00: scheduled__2024-07-23T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.201032+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.616+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-23 04:10:00+00:00, run_id=scheduled__2024-07-23T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340559+00:00, run_end_date=2024-07-29 08:54:40.616549+00:00, run_duration=0.27599, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-23 04:10:00+00:00, data_interval_end=2024-07-24 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.619+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.625+0900[0m] {[34mdagrun.py:[0m871} ERROR[0m - Task deadlock (no runnable tasks); marking run <DagRun movie @ 2024-07-24 04:10:00+00:00: scheduled__2024-07-24T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.201042+00:00. externally triggered: False> failed[0m
[[34m2024-07-29T17:54:40.625+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-24 04:10:00+00:00, run_id=scheduled__2024-07-24T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340571+00:00, run_end_date=2024-07-29 08:54:40.625746+00:00, run_duration=0.285175, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-24 04:10:00+00:00, data_interval_end=2024-07-25 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.627+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-25 04:10:00+00:00, run_after=2024-07-26 04:10:00+00:00[0m
[[34m2024-07-29T17:54:40.631+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.201052+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:40.632+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-29 08:54:40.340582+00:00, run_end_date=2024-07-29 08:54:40.632237+00:00, run_duration=0.291655, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:40.634+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T17:54:41.769+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T17:54:41.805+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.201061+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:41.805+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-29 08:54:41.744765+00:00, run_end_date=2024-07-29 08:54:41.805549+00:00, run_duration=0.060784, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:41.807+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T17:54:41.809+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.201071+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:41.809+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-29 08:54:41.744793+00:00, run_end_date=2024-07-29 08:54:41.809926+00:00, run_duration=0.065133, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:41.811+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T17:54:41.813+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-28 04:10:00+00:00: scheduled__2024-07-28T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:54:40.201080+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:54:41.813+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-28 04:10:00+00:00, run_id=scheduled__2024-07-28T04:10:00+00:00, run_start_date=2024-07-29 08:54:41.744805+00:00, run_end_date=2024-07-29 08:54:41.813865+00:00, run_duration=0.06906, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-28 04:10:00+00:00, data_interval_end=2024-07-29 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T17:54:41.815+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-29T17:56:45.577+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T17:56:45.631+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:56:45.632+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-29T17:56:45.632+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T17:56:45.632+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:56:45.653+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:56:45.653+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:45.653+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:56:45.653+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:45.662+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:46.804+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:56:46.901+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:46.946+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:56:46.947+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:47.545+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:56:48.196+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:49.563+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:56:49.658+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:49.705+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:56:49.706+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:50.287+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:56:50.951+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:56:50.951+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:56:50.955+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:56:47.595078+00:00, run_end_date=2024-07-29 08:56:47.738834+00:00, run_duration=0.143756, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=3033, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:56:45.633057+00:00, queued_by_job_id=3032, pid=311748[0m
[[34m2024-07-29T17:56:50.955+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:56:50.338947+00:00, run_end_date=2024-07-29 08:56:50.472843+00:00, run_duration=0.133896, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3035, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:56:45.633057+00:00, queued_by_job_id=3032, pid=311768[0m
[[34m2024-07-29T17:56:51.207+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-29T17:56:51.292+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 3 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:56:51.293+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-29T17:56:51.293+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T17:56:51.293+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-29T17:56:51.293+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:56:51.294+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:56:51.295+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:51.295+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:56:51.295+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:51.295+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:56:51.295+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:51.304+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:52.628+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:56:52.793+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:52.856+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:56:52.857+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:53.628+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:56:54.313+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:55.604+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:56:55.698+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:55.747+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:56:55.747+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:56.315+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:56:57.100+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:56:58.498+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:56:58.629+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:58.686+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:56:58.690+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:56:59.268+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:56:59.963+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-29T17:56:59.964+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:56:59.964+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:56:59.995+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:56:53.680212+00:00, run_end_date=2024-07-29 08:56:53.807096+00:00, run_duration=0.126884, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=3037, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:56:51.293917+00:00, queued_by_job_id=3032, pid=311790[0m
[[34m2024-07-29T17:56:59.996+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:56:56.379774+00:00, run_end_date=2024-07-29 08:56:56.531201+00:00, run_duration=0.151427, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=3039, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:56:51.293917+00:00, queued_by_job_id=3032, pid=311810[0m
[[34m2024-07-29T17:56:59.996+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:56:59.346505+00:00, run_end_date=2024-07-29 08:56:59.492398+00:00, run_duration=0.145893, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3041, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 08:56:51.293917+00:00, queued_by_job_id=3032, pid=311832[0m
[[34m2024-07-29T17:57:00.017+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T17:57:00.177+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:57:00.177+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-29T17:57:00.177+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:57:00.178+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T17:57:00.178+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:57:00.189+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:57:01.573+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:57:01.698+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:57:01.748+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:57:01.748+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:57:02.330+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:57:02.997+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-29T17:57:03.000+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:57:02.385669+00:00, run_end_date=2024-07-29 08:57:02.512154+00:00, run_duration=0.126485, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=3043, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 08:57:00.178116+00:00, queued_by_job_id=3032, pid=311854[0m
[[34m2024-07-29T17:57:04.370+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.task_err scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:57:04.390+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-29T17:57:04.391+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.task_err scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:57:04.394+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:57:04.397+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:57:04.412+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:57:05.784+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:57:05.878+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:57:05.933+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:57:05.934+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:57:06.514+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:57:07.213+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:57:07.218+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:57:06.570322+00:00, run_end_date=2024-07-29 08:57:06.718546+00:00, run_duration=0.148224, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3046, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 08:57:04.392241+00:00, queued_by_job_id=3032, pid=311880[0m
[[34m2024-07-29T17:57:07.395+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:57:07.395+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T17:57:07.395+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T17:57:07.396+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T17:57:07.396+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:57:07.405+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T17:57:08.848+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T17:57:08.936+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:57:08.979+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T17:57:08.979+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T17:57:09.495+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T17:57:10.120+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T17:57:10.124+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 08:57:09.551215+00:00, run_end_date=2024-07-29 08:57:09.696793+00:00, run_duration=0.145578, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3048, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 08:57:07.395809+00:00, queued_by_job_id=3032, pid=311903[0m
[[34m2024-07-29T17:57:10.249+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T17:57:10.272+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-29 08:56:45.572306+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T17:57:10.272+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-29 08:56:45.591046+00:00, run_end_date=2024-07-29 08:57:10.272433+00:00, run_duration=24.681387, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T17:57:10.275+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T18:02:00.150+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T18:07:00.287+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T18:12:00.422+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T18:17:00.560+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T18:22:00.697+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T18:22:08.147+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:22:08.147+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-29T18:22:08.147+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T18:22:08.147+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-29T18:22:08.147+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-29T18:22:08.147+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:22:08.148+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-29T18:22:08.148+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:08.149+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-29T18:22:08.149+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:08.149+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-29T18:22:08.149+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:08.149+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-29T18:22:08.149+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:08.159+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:09.246+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:22:09.334+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:09.383+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:22:09.384+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:09.930+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:22:10.586+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:11.646+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:22:11.721+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:11.764+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:22:11.764+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:12.256+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:22:12.861+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:14.097+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:22:14.183+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:14.232+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:22:14.233+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:14.817+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:22:15.459+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:16.669+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:22:16.765+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:16.809+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:22:16.810+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:17.459+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:22:18.148+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-29T18:22:18.148+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-29T18:22:18.148+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-29T18:22:18.149+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-29T18:22:18.152+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:22:15.570368+00:00, run_end_date=2024-07-29 09:22:15.696126+00:00, run_duration=0.125758, state=failed, executor_state=success, try_number=3, max_tries=3, job_id=3052, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:22:13.545809+00:00, queued_by_job_id=3004, pid=315415[0m
[[34m2024-07-29T18:22:18.152+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:22:12.305658+00:00, run_end_date=2024-07-29 09:22:12.429482+00:00, run_duration=0.123824, state=queued, executor_state=success, try_number=3, max_tries=3, job_id=3050, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:22:16.433312+00:00, queued_by_job_id=3004, pid=315391[0m
[[34m2024-07-29T18:22:18.153+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:22:14.879985+00:00, run_end_date=2024-07-29 09:22:15.006889+00:00, run_duration=0.126904, state=up_for_retry, executor_state=success, try_number=3, max_tries=3, job_id=3051, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:22:08.147976+00:00, queued_by_job_id=3032, pid=315412[0m
[[34m2024-07-29T18:22:18.153+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:22:17.515895+00:00, run_end_date=2024-07-29 09:22:17.655178+00:00, run_duration=0.139283, state=up_for_retry, executor_state=success, try_number=3, max_tries=3, job_id=3053, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:22:08.147976+00:00, queued_by_job_id=3032, pid=315433[0m
[[34m2024-07-29T18:22:18.416+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-29 09:22:07.132246+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T18:22:18.417+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-29 09:22:07.167034+00:00, run_end_date=2024-07-29 09:22:18.416960+00:00, run_duration=11.249926, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T18:22:18.420+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-29T18:22:18.448+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:22:18.448+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T18:22:18.449+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:22:18.450+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T18:22:18.450+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:18.459+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:22:19.679+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:22:19.764+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:19.804+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:22:19.804+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:22:20.343+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:22:21.081+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-29T18:22:21.085+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:22:20.406237+00:00, run_end_date=2024-07-29 09:22:20.525917+00:00, run_duration=0.11968, state=failed, executor_state=success, try_number=4, max_tries=3, job_id=3055, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:22:18.449683+00:00, queued_by_job_id=3032, pid=315447[0m
[[34m2024-07-29T18:22:21.310+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T18:22:21.332+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-29 09:22:07.132340+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T18:22:21.333+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-29 09:22:07.167134+00:00, run_end_date=2024-07-29 09:22:21.333081+00:00, run_duration=14.165947, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T18:22:21.335+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T18:22:22.480+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-29T18:27:00.835+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T18:29:01.789+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:01.789+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-29T18:29:01.789+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:01.790+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T18:29:01.790+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:01.800+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:02.935+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:29:03.014+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:03.054+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:29:03.055+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:03.551+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:29:04.181+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-29T18:29:04.185+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:29:03.598576+00:00, run_end_date=2024-07-29 09:29:03.716416+00:00, run_duration=0.11784, state=failed, executor_state=success, try_number=6, max_tries=5, job_id=3060, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:29:01.789812+00:00, queued_by_job_id=3032, pid=316431[0m
[[34m2024-07-29T18:29:04.359+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:04.360+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-29T18:29:04.360+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:04.362+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T18:29:04.362+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:04.369+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:05.735+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:29:05.844+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:05.892+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:29:05.892+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:06.402+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:29:07.028+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-29T18:29:07.031+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:29:06.451147+00:00, run_end_date=2024-07-29 09:29:06.571769+00:00, run_duration=0.120622, state=failed, executor_state=success, try_number=6, max_tries=5, job_id=3062, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:29:04.360974+00:00, queued_by_job_id=3032, pid=316452[0m
[[34m2024-07-29T18:29:07.240+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:07.241+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-29T18:29:07.241+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-29T18:29:07.241+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:07.252+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T18:29:07.253+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:07.253+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T18:29:07.253+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:07.270+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:08.588+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:29:08.704+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:08.750+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:29:08.751+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:09.330+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:29:09.999+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:11.207+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:29:11.292+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:11.337+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:29:11.338+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:11.894+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:29:12.701+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-29T18:29:12.701+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-29T18:29:12.707+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:29:09.382052+00:00, run_end_date=2024-07-29 09:29:09.508619+00:00, run_duration=0.126567, state=failed, executor_state=success, try_number=6, max_tries=5, job_id=3064, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:29:07.241974+00:00, queued_by_job_id=3032, pid=316474[0m
[[34m2024-07-29T18:29:12.707+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:29:11.951408+00:00, run_end_date=2024-07-29 09:29:12.110565+00:00, run_duration=0.159157, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3066, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 09:29:07.241974+00:00, queued_by_job_id=3032, pid=316494[0m
[[34m2024-07-29T18:29:12.902+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:12.903+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-29T18:29:12.903+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-29T18:29:12.903+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task_err scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:12.904+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T18:29:12.904+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:12.905+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T18:29:12.905+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:12.911+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:14.138+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:29:14.231+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:14.269+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:29:14.270+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:14.860+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:29:15.541+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:16.907+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:29:17.000+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:17.042+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:29:17.042+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:17.550+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:29:18.192+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-29T18:29:18.193+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-29T18:29:18.199+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:29:17.616638+00:00, run_end_date=2024-07-29 09:29:17.757775+00:00, run_duration=0.141137, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3070, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 09:29:12.904013+00:00, queued_by_job_id=3032, pid=316538[0m
[[34m2024-07-29T18:29:18.200+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:29:14.911382+00:00, run_end_date=2024-07-29 09:29:15.047057+00:00, run_duration=0.135675, state=failed, executor_state=success, try_number=6, max_tries=5, job_id=3068, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:29:12.904013+00:00, queued_by_job_id=3032, pid=316517[0m
[[34m2024-07-29T18:29:18.464+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-29T18:29:18.506+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:18.506+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T18:29:18.506+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:29:18.507+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T18:29:18.507+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:18.514+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task_err', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:29:19.741+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:29:19.847+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:19.895+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:29:19.895+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:29:20.473+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:29:21.110+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task_err', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-29T18:29:21.114+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task_err, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:29:20.531537+00:00, run_end_date=2024-07-29 09:29:20.682255+00:00, run_duration=0.150718, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3072, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 09:29:18.506809+00:00, queued_by_job_id=3032, pid=316561[0m
[[34m2024-07-29T18:29:21.239+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T18:29:21.257+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-29 09:28:55.919394+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T18:29:21.258+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-29 09:28:56.371330+00:00, run_end_date=2024-07-29 09:29:21.258134+00:00, run_duration=24.886804, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=8e55335d76cf5b9590751be65b9f7a37[0m
[[34m2024-07-29T18:29:21.260+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T18:32:01.169+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T18:37:01.300+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T18:42:01.456+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T18:46:02.030+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:46:02.030+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-29T18:46:02.030+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-29T18:46:02.030+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:46:02.032+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=7, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-29T18:46:02.032+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:02.032+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T18:46:02.032+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:02.041+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:03.145+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:46:03.232+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:03.271+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:46:03.271+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:03.777+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:46:04.591+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:05.748+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:46:05.840+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:05.889+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:46:05.890+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:06.407+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:46:07.063+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=7, map_index=-1)[0m
[[34m2024-07-29T18:46:07.064+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-29T18:46:07.067+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:46:03.834040+00:00, run_end_date=2024-07-29 09:46:04.009516+00:00, run_duration=0.175476, state=success, executor_state=success, try_number=7, max_tries=7, job_id=3074, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-29 09:46:02.031291+00:00, queued_by_job_id=3032, pid=318780[0m
[[34m2024-07-29T18:46:07.067+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:46:06.465028+00:00, run_end_date=2024-07-29 09:46:06.591325+00:00, run_duration=0.126297, state=success, executor_state=success, try_number=3, max_tries=3, job_id=3076, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-29 09:46:02.031291+00:00, queued_by_job_id=3032, pid=318800[0m
[[34m2024-07-29T18:46:07.257+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 3 tasks up for execution:
	<TaskInstance: movie.rm.dir scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.rm.dir scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.rm.dir scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:46:07.257+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-29T18:46:07.257+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-29T18:46:07.258+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-29T18:46:07.258+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.rm.dir scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.rm.dir scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.rm.dir scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:46:07.259+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T18:46:07.259+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:07.259+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T18:46:07.259+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:07.260+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T18:46:07.260+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:07.268+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:08.611+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:46:08.702+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:08.746+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:46:08.747+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:09.339+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.rm.dir scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:46:10.091+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:11.346+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:46:11.438+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:11.489+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:46:11.489+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:12.219+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.rm.dir scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:46:13.041+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:14.269+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:46:14.366+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:14.411+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:46:14.411+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:14.919+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.rm.dir scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:46:15.746+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:46:15.746+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:46:15.746+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:46:15.751+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=rm.dir, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:46:09.401004+00:00, run_end_date=2024-07-29 09:46:09.588342+00:00, run_duration=0.187338, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3078, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2024-07-29 09:46:07.258499+00:00, queued_by_job_id=3032, pid=318821[0m
[[34m2024-07-29T18:46:15.752+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=rm.dir, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:46:12.284468+00:00, run_end_date=2024-07-29 09:46:12.540164+00:00, run_duration=0.255696, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3080, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2024-07-29 09:46:07.258499+00:00, queued_by_job_id=3032, pid=318843[0m
[[34m2024-07-29T18:46:15.752+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=rm.dir, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:46:14.981225+00:00, run_end_date=2024-07-29 09:46:15.215985+00:00, run_duration=0.23476, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3082, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2024-07-29 09:46:07.258499+00:00, queued_by_job_id=3032, pid=318867[0m
[[34m2024-07-29T18:46:15.944+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: movie.rm.dir scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:46:15.944+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T18:46:15.944+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-29T18:46:15.945+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-29T18:46:15.945+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-29T18:46:15.945+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.rm.dir scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:46:15.948+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-29T18:46:15.948+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:15.948+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-29T18:46:15.948+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:15.948+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-29T18:46:15.949+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:15.949+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-29T18:46:15.949+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:15.956+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:17.295+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:46:17.383+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:17.426+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:46:17.426+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:17.893+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.rm.dir scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:46:18.594+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:20.103+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:46:20.216+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:20.282+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:46:20.282+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:20.831+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:46:42.004+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:46:43.794+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:46:43.919+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:43.985+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:46:43.986+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:46:44.789+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:47:07.494+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:47:09.288+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:47:09.448+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:47:09.526+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:47:09.527+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:47:10.305+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:47:33.119+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:47:33.121+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:47:33.122+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:47:33.122+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:47:33.141+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:46:20.891949+00:00, run_end_date=2024-07-29 09:46:41.495055+00:00, run_duration=20.603106, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3085, pool=default_pool, queue=default, priority_weight=7, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 09:46:15.946007+00:00, queued_by_job_id=3032, pid=318912[0m
[[34m2024-07-29T18:47:33.141+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:46:44.855851+00:00, run_end_date=2024-07-29 09:47:06.844073+00:00, run_duration=21.988222, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3087, pool=default_pool, queue=default, priority_weight=7, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 09:46:15.946007+00:00, queued_by_job_id=3032, pid=319055[0m
[[34m2024-07-29T18:47:33.142+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=rm.dir, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:46:17.961735+00:00, run_end_date=2024-07-29 09:46:18.110589+00:00, run_duration=0.148854, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3084, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2024-07-29 09:46:15.946007+00:00, queued_by_job_id=3032, pid=318890[0m
[[34m2024-07-29T18:47:33.142+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:47:10.387170+00:00, run_end_date=2024-07-29 09:47:32.584800+00:00, run_duration=22.19763, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3097, pool=default_pool, queue=default, priority_weight=7, operator=PythonVirtualenvOperator, queued_dttm=2024-07-29 09:46:15.946007+00:00, queued_by_job_id=3032, pid=319219[0m
[[34m2024-07-29T18:47:33.153+0900[0m] {[34mmanager.py:[0m285} ERROR[0m - DagFileProcessorManager (PID=309558) last sent a heartbeat 77.27 seconds ago! Restarting it[0m
[[34m2024-07-29T18:47:33.156+0900[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 309558. PIDs of all processes in the group: [309558][0m
[[34m2024-07-29T18:47:33.156+0900[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 309558[0m
[[34m2024-07-29T18:47:33.330+0900[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Process psutil.Process(pid=309558, status='terminated', exitcode=0, started='17:45:23') (309558) terminated with exit code 0[0m
[[34m2024-07-29T18:47:33.334+0900[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 319327[0m
[[34m2024-07-29T18:47:33.348+0900[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2024-07-29T18:47:33.379+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[2024-07-29T18:47:33.383+0900] {manager.py:393} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-07-29T18:47:36.096+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 3 tasks up for execution:
	<TaskInstance: movie.b scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:47:36.096+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-29T18:47:36.096+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-29T18:47:36.096+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-29T18:47:36.097+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.b scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-29T18:47:36.098+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='b', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T18:47:36.099+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'b', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:47:36.099+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T18:47:36.099+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:47:36.099+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-29T18:47:36.099+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:47:36.111+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'b', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:47:37.376+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:47:37.472+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:47:37.518+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:47:37.519+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:47:38.010+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.b scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:47:38.744+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:47:39.957+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:47:40.042+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:47:40.082+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:47:40.083+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:47:40.593+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:47:41.253+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-29T18:47:42.347+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-29T18:47:42.464+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:47:42.518+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-29T18:47:42.519+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-29T18:47:43.117+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-29T18:47:43.797+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='b', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:47:43.797+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:47:43.797+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-29T18:47:43.801+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=b, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:47:38.065289+00:00, run_end_date=2024-07-29 09:47:38.242011+00:00, run_duration=0.176722, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3102, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 09:47:36.097586+00:00, queued_by_job_id=3032, pid=319354[0m
[[34m2024-07-29T18:47:43.802+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:47:40.648667+00:00, run_end_date=2024-07-29 09:47:40.802541+00:00, run_duration=0.153874, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3103, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 09:47:36.097586+00:00, queued_by_job_id=3032, pid=319367[0m
[[34m2024-07-29T18:47:43.802+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-29 09:47:43.175257+00:00, run_end_date=2024-07-29 09:47:43.335309+00:00, run_duration=0.160052, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3104, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-29 09:47:36.097586+00:00, queued_by_job_id=3032, pid=319381[0m
[[34m2024-07-29T18:47:43.974+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-29 09:46:00.554771+00:00. externally triggered: False> successful[0m
[[34m2024-07-29T18:47:43.975+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-29 09:46:00.814407+00:00, run_end_date=2024-07-29 09:47:43.975181+00:00, run_duration=103.160774, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=24b41a494feb9725faf3ad944e6af1dd[0m
[[34m2024-07-29T18:47:43.977+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-29T22:16:16.541+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T22:21:16.674+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T22:26:16.809+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T22:31:17.044+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T22:36:17.177+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T22:41:17.310+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T22:46:17.451+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T22:51:17.584+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T22:56:17.724+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:01:17.856+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:06:17.992+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:11:18.126+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:16:18.266+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:21:18.408+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:26:18.543+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:31:18.886+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:36:19.027+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:41:19.159+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:46:19.250+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:51:19.486+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-29T23:56:19.619+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:01:19.755+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:06:19.890+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:11:20.044+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:16:20.280+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:21:20.414+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:26:20.566+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:31:20.703+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:36:20.836+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:41:20.921+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:46:21.018+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:51:21.151+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T00:56:21.290+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T01:01:21.387+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T01:06:21.523+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T01:11:21.659+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T01:16:21.795+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T08:43:35.186+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T08:48:35.321+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T08:53:35.383+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T08:58:35.520+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:03:35.660+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:08:35.797+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:13:35.938+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:18:35.954+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:23:36.106+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:28:36.197+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:33:36.334+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:38:36.466+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:43:36.601+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:48:36.741+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:53:36.890+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T09:58:37.029+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:03:37.163+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:08:37.297+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:13:37.540+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:18:37.673+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:20:49.094+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.b scheduled__2024-07-25T04:10:00+00:00 [success]>. Marking it as removed.[0m
[[34m2024-07-30T10:20:49.097+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.task_err scheduled__2024-07-25T04:10:00+00:00 [skipped]>. Marking it as removed.[0m
[[34m2024-07-30T10:20:49.107+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.b scheduled__2024-07-26T04:10:00+00:00 [success]>. Marking it as removed.[0m
[[34m2024-07-30T10:20:49.108+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.task_err scheduled__2024-07-26T04:10:00+00:00 [skipped]>. Marking it as removed.[0m
[[34m2024-07-30T10:20:49.117+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.b scheduled__2024-07-27T04:10:00+00:00 [success]>. Marking it as removed.[0m
[[34m2024-07-30T10:20:49.118+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.task_err scheduled__2024-07-27T04:10:00+00:00 [skipped]>. Marking it as removed.[0m
[[34m2024-07-30T10:20:49.127+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.b scheduled__2024-07-28T04:10:00+00:00 [success]>. Marking it as removed.[0m
[[34m2024-07-30T10:20:49.128+0900[0m] {[34mdagrun.py:[0m940} ERROR[0m - Failed to get task for ti <TaskInstance: movie.task_err scheduled__2024-07-28T04:10:00+00:00 [skipped]>. Marking it as removed.[0m
[[34m2024-07-30T10:20:49.144+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: movie.task.echo scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task.echo scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task.echo scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task.echo scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:20:49.145+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T10:20:49.145+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T10:20:49.145+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T10:20:49.145+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T10:20:49.145+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.task.echo scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task.echo scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task.echo scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.task.echo scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:20:49.147+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task.echo', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-30T10:20:49.147+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task.echo', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:20:49.147+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task.echo', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-30T10:20:49.147+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task.echo', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:20:49.147+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task.echo', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-30T10:20:49.148+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task.echo', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:20:49.148+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='task.echo', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-30T10:20:49.148+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'task.echo', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:20:49.156+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task.echo', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:20:50.841+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:20:50.930+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:20:50.977+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:20:50.978+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:20:51.456+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task.echo scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:20:51.900+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task.echo', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:20:53.118+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:20:53.202+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:20:53.241+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:20:53.241+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:20:53.735+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task.echo scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:20:54.160+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task.echo', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:20:55.235+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:20:55.326+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:20:55.366+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:20:55.367+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:20:55.910+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task.echo scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:20:56.339+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'task.echo', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:20:57.443+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:20:57.523+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:20:57.563+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:20:57.564+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:20:58.044+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.task.echo scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:20:58.502+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task.echo', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-30T10:20:58.503+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task.echo', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-30T10:20:58.503+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task.echo', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-30T10:20:58.503+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='task.echo', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-30T10:20:58.506+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task.echo, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:20:51.510742+00:00, run_end_date=2024-07-30 01:20:51.510742+00:00, run_duration=0.0, state=skipped, executor_state=success, try_number=1, max_tries=1, job_id=3105, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-30 01:20:49.145871+00:00, queued_by_job_id=3032, pid=None[0m
[[34m2024-07-30T10:20:58.506+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task.echo, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:20:53.790330+00:00, run_end_date=2024-07-30 01:20:53.790330+00:00, run_duration=0.0, state=skipped, executor_state=success, try_number=1, max_tries=1, job_id=3106, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-30 01:20:49.145871+00:00, queued_by_job_id=3032, pid=None[0m
[[34m2024-07-30T10:20:58.506+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task.echo, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:20:55.964537+00:00, run_end_date=2024-07-30 01:20:55.964537+00:00, run_duration=0.0, state=skipped, executor_state=success, try_number=1, max_tries=1, job_id=3107, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-30 01:20:49.145871+00:00, queued_by_job_id=3032, pid=None[0m
[[34m2024-07-30T10:20:58.507+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=task.echo, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:20:58.112749+00:00, run_end_date=2024-07-30 01:20:58.112749+00:00, run_duration=0.0, state=skipped, executor_state=success, try_number=1, max_tries=1, job_id=3108, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-07-30 01:20:49.145871+00:00, queued_by_job_id=3032, pid=None[0m
[[34m2024-07-30T10:23:37.805+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:27:38.882+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:27:25.005909+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:27:38.882+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-30 01:27:25.497419+00:00, run_end_date=2024-07-30 01:27:38.882747+00:00, run_duration=13.385328, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=bc8e0827d8bb20648ae9e541fe06760c[0m
[[34m2024-07-30T10:27:38.890+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-30T10:27:40.041+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:27:41.245+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:27:25.006028+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:27:41.246+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-30 01:27:25.497466+00:00, run_end_date=2024-07-30 01:27:41.246045+00:00, run_duration=15.748579, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=bc8e0827d8bb20648ae9e541fe06760c[0m
[[34m2024-07-30T10:27:41.250+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:27:41.601+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:27:42.771+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:27:44.214+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:27:25.006043+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:27:44.215+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-30 01:27:25.497480+00:00, run_end_date=2024-07-30 01:27:44.214961+00:00, run_duration=18.717481, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=bc8e0827d8bb20648ae9e541fe06760c[0m
[[34m2024-07-30T10:27:44.220+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:27:45.284+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:28:37.938+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:30:38.229+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:30:24.512857+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:30:38.229+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-30 01:30:24.681104+00:00, run_end_date=2024-07-30 01:30:38.229657+00:00, run_duration=13.548553, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:30:38.232+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-30T10:30:39.388+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:30:40.558+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:30:40.576+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:30:24.512901+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:30:40.576+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-30 01:30:24.681134+00:00, run_end_date=2024-07-30 01:30:40.576632+00:00, run_duration=15.895498, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:30:40.578+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:30:41.729+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:30:43.113+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:30:43.133+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:30:24.512914+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:30:43.134+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-30 01:30:24.681147+00:00, run_end_date=2024-07-30 01:30:43.134525+00:00, run_duration=18.453378, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:30:43.138+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:30:44.281+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:30:58.373+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:30:55.946501+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:30:58.374+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-30 01:30:55.972659+00:00, run_end_date=2024-07-30 01:30:58.374551+00:00, run_duration=2.401892, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:30:58.377+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-30T10:30:59.526+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:31:00.693+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:31:00.712+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:30:55.946532+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:31:00.712+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-30 01:30:55.972728+00:00, run_end_date=2024-07-30 01:31:00.712550+00:00, run_duration=4.739822, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:31:00.714+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:31:01.854+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:31:02.367+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:31:03.545+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:30:55.946545+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:31:03.546+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-30 01:30:55.972743+00:00, run_end_date=2024-07-30 01:31:03.546219+00:00, run_duration=7.573476, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:31:03.548+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:31:04.635+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:31:05.797+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-28 04:10:00+00:00: scheduled__2024-07-28T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:30:55.946570+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:31:05.797+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-28 04:10:00+00:00, run_id=scheduled__2024-07-28T04:10:00+00:00, run_start_date=2024-07-30 01:30:55.972756+00:00, run_end_date=2024-07-30 01:31:05.797714+00:00, run_duration=9.824958, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-28 04:10:00+00:00, data_interval_end=2024-07-29 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:31:05.799+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:32:53.032+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 8 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:32:53.032+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T10:32:53.033+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T10:32:53.033+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T10:32:53.033+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T10:32:53.033+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T10:32:53.033+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-30T10:32:53.033+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-30T10:32:53.033+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T10:32:53.034+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:32:53.040+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=10, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-30T10:32:53.040+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:53.040+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=10, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-30T10:32:53.040+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:53.041+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=10, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-30T10:32:53.041+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:53.041+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=10, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-30T10:32:53.041+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:53.041+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:32:53.041+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:53.042+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:32:53.042+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:53.042+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:32:53.042+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:53.042+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:32:53.042+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:53.050+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:54.156+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:32:54.236+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:32:54.274+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:32:54.274+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:32:54.765+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:32:55.465+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:56.784+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:32:56.906+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:32:56.966+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:32:56.966+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:32:57.505+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:32:58.210+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:32:59.505+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:32:59.607+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:32:59.656+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:32:59.656+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:00.254+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:01.077+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:02.390+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:02.477+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:02.521+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:02.521+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:03.090+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:03.837+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:05.215+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:05.304+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:05.346+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:05.347+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:05.847+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:06.453+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:07.625+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:07.744+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:07.799+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:07.800+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:08.478+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:09.189+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:10.424+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:10.527+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:10.570+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:10.570+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:11.121+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:11.804+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:13.306+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:13.405+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:13.451+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:13.452+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:14.039+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:14.728+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=10, map_index=-1)[0m
[[34m2024-07-30T10:33:14.728+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=10, map_index=-1)[0m
[[34m2024-07-30T10:33:14.729+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=10, map_index=-1)[0m
[[34m2024-07-30T10:33:14.729+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=10, map_index=-1)[0m
[[34m2024-07-30T10:33:14.729+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T10:33:14.729+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T10:33:14.729+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T10:33:14.729+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T10:33:14.744+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:32:54.811283+00:00, run_end_date=2024-07-30 01:32:54.991234+00:00, run_duration=0.179951, state=success, executor_state=success, try_number=10, max_tries=10, job_id=3129, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-30 01:32:53.034911+00:00, queued_by_job_id=3032, pid=360941[0m
[[34m2024-07-30T10:33:14.744+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:05.901987+00:00, run_end_date=2024-07-30 01:33:06.025404+00:00, run_duration=0.123417, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3136, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 01:32:53.034911+00:00, queued_by_job_id=3032, pid=361045[0m
[[34m2024-07-30T10:33:14.744+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:32:57.584398+00:00, run_end_date=2024-07-30 01:32:57.747812+00:00, run_duration=0.163414, state=success, executor_state=success, try_number=10, max_tries=10, job_id=3131, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-30 01:32:53.034911+00:00, queued_by_job_id=3032, pid=360965[0m
[[34m2024-07-30T10:33:14.745+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:08.538842+00:00, run_end_date=2024-07-30 01:33:08.689258+00:00, run_duration=0.150416, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3137, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 01:32:53.034911+00:00, queued_by_job_id=3032, pid=361074[0m
[[34m2024-07-30T10:33:14.745+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:03.150026+00:00, run_end_date=2024-07-30 01:33:03.364515+00:00, run_duration=0.214489, state=success, executor_state=success, try_number=10, max_tries=10, job_id=3135, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-30 01:32:53.034911+00:00, queued_by_job_id=3032, pid=361008[0m
[[34m2024-07-30T10:33:14.745+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:14.101093+00:00, run_end_date=2024-07-30 01:33:14.246388+00:00, run_duration=0.145295, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3139, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 01:32:53.034911+00:00, queued_by_job_id=3032, pid=361098[0m
[[34m2024-07-30T10:33:14.746+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:00.322418+00:00, run_end_date=2024-07-30 01:33:00.543979+00:00, run_duration=0.221561, state=success, executor_state=success, try_number=10, max_tries=10, job_id=3133, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-30 01:32:53.034911+00:00, queued_by_job_id=3032, pid=360986[0m
[[34m2024-07-30T10:33:14.746+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:11.175968+00:00, run_end_date=2024-07-30 01:33:11.308456+00:00, run_duration=0.132488, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3138, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 01:32:53.034911+00:00, queued_by_job_id=3032, pid=361086[0m
[[34m2024-07-30T10:33:14.952+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 3 tasks up for execution:
	<TaskInstance: movie.rm.dir scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.rm.dir scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:14.953+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T10:33:14.953+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T10:33:14.953+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T10:33:14.954+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.rm.dir scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.rm.dir scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:14.956+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T10:33:14.956+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:14.957+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T10:33:14.957+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:14.957+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2024-07-30T10:33:14.957+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:14.970+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:16.430+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:16.522+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:16.572+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:16.573+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:17.167+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.rm.dir scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:17.997+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:19.347+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:19.469+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:19.531+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:19.532+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:20.195+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.rm.dir scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:20.968+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:22.318+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:22.433+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:22.502+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:22.503+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:23.175+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:44.392+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:33:44.392+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:33:44.393+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:33:44.400+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=rm.dir, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:17.243150+00:00, run_end_date=2024-07-30 01:33:17.505378+00:00, run_duration=0.262228, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3140, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-07-30 01:33:14.954816+00:00, queued_by_job_id=3032, pid=361109[0m
[[34m2024-07-30T10:33:44.401+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:23.245460+00:00, run_end_date=2024-07-30 01:33:43.899569+00:00, run_duration=20.654109, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3142, pool=default_pool, queue=default, priority_weight=6, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 01:33:14.954816+00:00, queued_by_job_id=3032, pid=361137[0m
[[34m2024-07-30T10:33:44.401+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=rm.dir, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:20.253341+00:00, run_end_date=2024-07-30 01:33:20.462138+00:00, run_duration=0.208797, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3141, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-07-30 01:33:14.954816+00:00, queued_by_job_id=3032, pid=361124[0m
[[34m2024-07-30T10:33:44.429+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:33:44.593+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:44.593+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T10:33:44.593+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:44.595+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T10:33:44.595+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:44.607+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:46.056+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:46.149+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:46.210+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:46.211+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:46.891+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:47.680+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:33:47.686+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:46.974690+00:00, run_end_date=2024-07-30 01:33:47.159335+00:00, run_duration=0.184645, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3144, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2024-07-30 01:33:44.593958+00:00, queued_by_job_id=3032, pid=361279[0m
[[34m2024-07-30T10:33:47.856+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.c scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:47.857+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T10:33:47.857+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T10:33:47.857+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.c scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:47.858+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:33:47.858+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:47.858+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:33:47.858+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:47.870+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:49.112+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:49.212+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:49.281+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:49.282+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:49.894+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:50.771+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:52.167+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:52.285+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:52.336+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:52.336+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:53.163+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:53.916+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:33:53.916+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:33:53.919+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:49.952640+00:00, run_end_date=2024-07-30 01:33:50.205041+00:00, run_duration=0.252401, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3145, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 01:33:47.857787+00:00, queued_by_job_id=3032, pid=361304[0m
[[34m2024-07-30T10:33:53.919+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:53.246574+00:00, run_end_date=2024-07-30 01:33:53.445322+00:00, run_duration=0.198748, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3147, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 01:33:47.857787+00:00, queued_by_job_id=3032, pid=361337[0m
[[34m2024-07-30T10:33:54.091+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:54.091+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T10:33:54.091+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:54.092+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T10:33:54.092+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:54.098+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:55.478+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:55.577+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:55.622+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:55.622+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:56.246+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:33:56.984+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:33:56.988+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:56.307271+00:00, run_end_date=2024-07-30 01:33:56.481012+00:00, run_duration=0.173741, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3148, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2024-07-30 01:33:54.091740+00:00, queued_by_job_id=3032, pid=361382[0m
[[34m2024-07-30T10:33:57.225+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:32:52.030270+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:33:57.225+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-30 01:32:52.680960+00:00, run_end_date=2024-07-30 01:33:57.225896+00:00, run_duration=64.544936, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:33:57.228+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:33:57.255+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:57.255+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T10:33:57.256+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T10:33:57.256+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:33:57.257+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:33:57.257+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:57.257+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:33:57.257+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:57.266+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:33:58.666+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:33:58.761+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:58.814+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:33:58.815+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:33:59.388+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:34:00.223+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:34:01.603+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:34:01.707+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:34:01.762+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:34:01.762+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:34:02.479+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:34:03.231+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:34:03.231+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:34:03.234+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:33:59.447870+00:00, run_end_date=2024-07-30 01:33:59.659841+00:00, run_duration=0.211971, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3149, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 01:33:57.256445+00:00, queued_by_job_id=3032, pid=361398[0m
[[34m2024-07-30T10:34:03.234+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:34:02.572075+00:00, run_end_date=2024-07-30 01:34:02.749309+00:00, run_duration=0.177234, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3150, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 01:33:57.256445+00:00, queued_by_job_id=3032, pid=361409[0m
[[34m2024-07-30T10:34:03.376+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:34:04.549+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:34:04.571+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:32:52.030282+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:34:04.572+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-30 01:32:52.680983+00:00, run_end_date=2024-07-30 01:34:04.572090+00:00, run_duration=71.891107, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:34:04.574+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:34:05.726+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:34:11.890+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:34:11.890+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T10:34:11.890+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:34:11.892+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=2, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T10:34:11.893+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:34:11.902+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:34:13.717+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:34:13.843+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:34:13.902+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:34:13.903+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:34:14.610+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:34:15.360+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-30T10:34:15.363+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:34:14.676375+00:00, run_end_date=2024-07-30 01:34:14.828594+00:00, run_duration=0.152219, state=success, executor_state=success, try_number=2, max_tries=2, job_id=3152, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2024-07-30 01:34:11.891302+00:00, queued_by_job_id=3032, pid=361455[0m
[[34m2024-07-30T10:34:20.507+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:32:52.030225+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:34:20.507+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-30 01:32:52.680907+00:00, run_end_date=2024-07-30 01:34:20.507927+00:00, run_duration=87.82702, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=395de4d304f46bcc09ee202fa5eaeaa8[0m
[[34m2024-07-30T10:34:20.510+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-30T10:34:21.761+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:34:23.021+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:34:24.179+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:38:44.566+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:43:44.702+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:46:18.568+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 8 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:46:18.568+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T10:46:18.568+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T10:46:18.568+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T10:46:18.568+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T10:46:18.568+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T10:46:18.568+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-30T10:46:18.568+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-30T10:46:18.569+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T10:46:18.569+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:46:18.570+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=11, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-30T10:46:18.571+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:18.571+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=11, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-30T10:46:18.571+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:18.571+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=11, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-30T10:46:18.571+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:18.571+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=11, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-30T10:46:18.571+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:18.572+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=7, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:46:18.572+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:18.572+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=7, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:46:18.572+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:18.572+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=7, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:46:18.572+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:18.572+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=7, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:46:18.572+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:18.579+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:19.614+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:46:19.691+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:19.730+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:46:19.731+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:20.217+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:46:20.989+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:22.310+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:46:22.420+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:22.473+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:46:22.474+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:23.017+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:46:23.793+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:25.049+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:46:25.151+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:25.205+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:46:25.205+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:25.807+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:46:26.563+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:27.923+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:46:28.031+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:28.073+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:46:28.073+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:28.655+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:46:29.416+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:30.782+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:46:30.909+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:30.957+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:46:30.958+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:31.506+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:46:32.202+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:33.641+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:46:33.759+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:33.804+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:46:33.805+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:34.370+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:46:35.026+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:36.460+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:46:36.567+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:36.613+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:46:36.613+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:37.264+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:46:38.002+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:39.186+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:46:39.269+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:39.305+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:46:39.305+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:39.807+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:46:40.439+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=11, map_index=-1)[0m
[[34m2024-07-30T10:46:40.439+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=11, map_index=-1)[0m
[[34m2024-07-30T10:46:40.440+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=11, map_index=-1)[0m
[[34m2024-07-30T10:46:40.440+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=11, map_index=-1)[0m
[[34m2024-07-30T10:46:40.440+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=7, map_index=-1)[0m
[[34m2024-07-30T10:46:40.440+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=7, map_index=-1)[0m
[[34m2024-07-30T10:46:40.440+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=7, map_index=-1)[0m
[[34m2024-07-30T10:46:40.440+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=7, map_index=-1)[0m
[[34m2024-07-30T10:46:40.444+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:46:20.265153+00:00, run_end_date=2024-07-30 01:46:20.458896+00:00, run_duration=0.193743, state=success, executor_state=success, try_number=11, max_tries=11, job_id=3157, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-30 01:46:18.569761+00:00, queued_by_job_id=3032, pid=363292[0m
[[34m2024-07-30T10:46:40.444+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:46:31.595665+00:00, run_end_date=2024-07-30 01:46:31.735379+00:00, run_duration=0.139714, state=success, executor_state=success, try_number=7, max_tries=7, job_id=3165, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 01:46:18.569761+00:00, queued_by_job_id=3032, pid=363385[0m
[[34m2024-07-30T10:46:40.444+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:46:23.071341+00:00, run_end_date=2024-07-30 01:46:23.255336+00:00, run_duration=0.183995, state=success, executor_state=success, try_number=11, max_tries=11, job_id=3159, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-30 01:46:18.569761+00:00, queued_by_job_id=3032, pid=363312[0m
[[34m2024-07-30T10:46:40.445+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:46:34.428627+00:00, run_end_date=2024-07-30 01:46:34.560971+00:00, run_duration=0.132344, state=success, executor_state=success, try_number=7, max_tries=7, job_id=3167, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 01:46:18.569761+00:00, queued_by_job_id=3032, pid=363408[0m
[[34m2024-07-30T10:46:40.445+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:46:28.715099+00:00, run_end_date=2024-07-30 01:46:28.892028+00:00, run_duration=0.176929, state=success, executor_state=success, try_number=11, max_tries=11, job_id=3163, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-30 01:46:18.569761+00:00, queued_by_job_id=3032, pid=363359[0m
[[34m2024-07-30T10:46:40.445+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:46:39.862399+00:00, run_end_date=2024-07-30 01:46:39.980501+00:00, run_duration=0.118102, state=success, executor_state=success, try_number=7, max_tries=7, job_id=3170, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 01:46:18.569761+00:00, queued_by_job_id=3032, pid=363473[0m
[[34m2024-07-30T10:46:40.445+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:46:25.872404+00:00, run_end_date=2024-07-30 01:46:26.065234+00:00, run_duration=0.19283, state=success, executor_state=success, try_number=11, max_tries=11, job_id=3161, pool=default_pool, queue=default, priority_weight=9, operator=BranchPythonOperator, queued_dttm=2024-07-30 01:46:18.569761+00:00, queued_by_job_id=3032, pid=363336[0m
[[34m2024-07-30T10:46:40.445+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:46:37.340564+00:00, run_end_date=2024-07-30 01:46:37.501652+00:00, run_duration=0.161088, state=success, executor_state=success, try_number=7, max_tries=7, job_id=3169, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 01:46:18.569761+00:00, queued_by_job_id=3032, pid=363429[0m
[[34m2024-07-30T10:46:40.640+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:46:40.640+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T10:46:40.640+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T10:46:40.640+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:46:40.641+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2024-07-30T10:46:40.642+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:40.642+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2024-07-30T10:46:40.642+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:40.652+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:46:42.053+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:46:42.160+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:42.220+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:46:42.220+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:46:42.789+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:47:03.220+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:47:04.784+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:47:04.900+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:47:04.959+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:47:04.959+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:47:05.513+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:47:25.416+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-30T10:47:25.417+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-30T10:47:25.421+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:46:42.858328+00:00, run_end_date=2024-07-30 01:47:02.781222+00:00, run_duration=19.922894, state=success, executor_state=success, try_number=3, max_tries=3, job_id=3171, pool=default_pool, queue=default, priority_weight=6, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 01:46:40.641103+00:00, queued_by_job_id=3032, pid=363495[0m
[[34m2024-07-30T10:47:25.421+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:47:05.570175+00:00, run_end_date=2024-07-30 01:47:24.822890+00:00, run_duration=19.252715, state=success, executor_state=success, try_number=3, max_tries=3, job_id=3173, pool=default_pool, queue=default, priority_weight=6, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 01:46:40.641103+00:00, queued_by_job_id=3032, pid=363636[0m
[[34m2024-07-30T10:47:25.655+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 3 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:47:25.656+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T10:47:25.656+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T10:47:25.656+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T10:47:25.656+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T10:47:25.659+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T10:47:25.659+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:47:25.659+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:47:25.659+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:47:25.659+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T10:47:25.660+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:47:25.667+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:47:27.030+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:47:27.180+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:47:27.241+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:47:27.242+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:47:28.012+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:47:28.785+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:47:30.074+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:47:30.162+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:47:30.217+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:47:30.218+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:47:30.884+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:47:31.766+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T10:47:33.140+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T10:47:33.270+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:47:33.358+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T10:47:33.359+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T10:47:34.328+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T10:47:35.247+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-30T10:47:35.248+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-30T10:47:35.248+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-30T10:47:35.259+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:47:30.943532+00:00, run_end_date=2024-07-30 01:47:31.120609+00:00, run_duration=0.177077, state=success, executor_state=success, try_number=3, max_tries=3, job_id=3178, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 01:47:25.657321+00:00, queued_by_job_id=3032, pid=363864[0m
[[34m2024-07-30T10:47:35.259+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:47:34.429635+00:00, run_end_date=2024-07-30 01:47:34.626491+00:00, run_duration=0.196856, state=success, executor_state=success, try_number=3, max_tries=3, job_id=3180, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 01:47:25.657321+00:00, queued_by_job_id=3032, pid=363886[0m
[[34m2024-07-30T10:47:35.260+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 01:47:28.071893+00:00, run_end_date=2024-07-30 01:47:28.261903+00:00, run_duration=0.19001, state=success, executor_state=success, try_number=3, max_tries=3, job_id=3176, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2024-07-30 01:47:25.657321+00:00, queued_by_job_id=3032, pid=363841[0m
[[34m2024-07-30T10:47:36.814+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:46:17.665190+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:47:36.814+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-30 01:46:18.206833+00:00, run_end_date=2024-07-30 01:47:36.814536+00:00, run_duration=78.607703, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=16a207607bb600e64d1bbe090d8b1cba[0m
[[34m2024-07-30T10:47:36.818+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-30T10:47:38.066+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:47:38.090+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:46:17.665286+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:47:38.090+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-30 01:46:18.206865+00:00, run_end_date=2024-07-30 01:47:38.090527+00:00, run_duration=79.883662, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=16a207607bb600e64d1bbe090d8b1cba[0m
[[34m2024-07-30T10:47:38.093+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T10:47:39.236+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:47:40.708+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T10:47:43.053+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-30 01:46:17.665303+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T10:47:43.054+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-30 01:46:18.206878+00:00, run_end_date=2024-07-30 01:47:43.054218+00:00, run_duration=84.84734, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=16a207607bb600e64d1bbe090d8b1cba[0m
[[34m2024-07-30T10:47:43.057+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T10:48:44.842+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:53:45.084+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T10:58:45.221+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:03:45.359+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:06:56.947+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 8 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:06:56.947+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T11:06:56.947+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:06:56.947+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:06:56.948+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:06:56.948+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T11:06:56.948+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-30T11:06:56.948+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-30T11:06:56.948+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T11:06:56.948+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:06:56.950+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=12, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:06:56.950+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:06:56.950+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=12, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:06:56.951+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:06:56.951+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=12, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:06:56.951+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:06:56.951+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=12, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:06:56.951+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:06:56.951+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=8, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:06:56.951+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:06:56.952+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=8, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:06:56.952+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:06:56.952+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=8, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:06:56.952+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:06:56.952+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=8, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:06:56.952+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:06:56.959+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:06:58.043+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:06:58.132+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:06:58.171+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:06:58.172+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:06:58.657+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:06:59.331+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:07:00.558+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:07:00.667+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:00.715+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:07:00.715+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:01.236+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:07:01.902+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:07:03.021+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:07:03.128+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:03.172+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:07:03.172+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:03.777+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:07:04.495+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:07:05.618+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:07:05.704+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:05.746+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:07:05.747+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:06.239+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:07:06.913+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:07:08.034+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:07:08.124+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:08.172+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:07:08.172+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:08.662+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:07:09.286+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:07:10.382+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:07:10.468+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:10.508+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:07:10.509+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:11.014+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:07:11.651+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:07:12.818+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:07:12.906+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:12.952+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:07:12.953+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:13.457+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:07:14.065+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:07:15.220+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:07:15.324+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:15.368+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:07:15.368+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:07:15.990+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:07:16.631+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=12, map_index=-1)[0m
[[34m2024-07-30T11:07:16.631+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=12, map_index=-1)[0m
[[34m2024-07-30T11:07:16.632+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=12, map_index=-1)[0m
[[34m2024-07-30T11:07:16.632+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=12, map_index=-1)[0m
[[34m2024-07-30T11:07:16.632+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=8, map_index=-1)[0m
[[34m2024-07-30T11:07:16.632+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=8, map_index=-1)[0m
[[34m2024-07-30T11:07:16.632+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=8, map_index=-1)[0m
[[34m2024-07-30T11:07:16.632+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=8, map_index=-1)[0m
[[34m2024-07-30T11:07:16.637+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:06:58.703932+00:00, run_end_date=2024-07-30 02:06:58.875169+00:00, run_duration=0.171237, state=success, executor_state=success, try_number=12, max_tries=12, job_id=3186, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:06:56.949266+00:00, queued_by_job_id=3032, pid=366763[0m
[[34m2024-07-30T11:07:16.637+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:07:08.711078+00:00, run_end_date=2024-07-30 02:07:08.821011+00:00, run_duration=0.109933, state=success, executor_state=success, try_number=8, max_tries=8, job_id=3190, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:06:56.949266+00:00, queued_by_job_id=3032, pid=366815[0m
[[34m2024-07-30T11:07:16.637+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:07:01.282890+00:00, run_end_date=2024-07-30 02:07:01.445387+00:00, run_duration=0.162497, state=success, executor_state=success, try_number=12, max_tries=12, job_id=3187, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:06:56.949266+00:00, queued_by_job_id=3032, pid=366776[0m
[[34m2024-07-30T11:07:16.637+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:07:11.070753+00:00, run_end_date=2024-07-30 02:07:11.183050+00:00, run_duration=0.112297, state=success, executor_state=success, try_number=8, max_tries=8, job_id=3191, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:06:56.949266+00:00, queued_by_job_id=3032, pid=366828[0m
[[34m2024-07-30T11:07:16.637+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:07:06.286190+00:00, run_end_date=2024-07-30 02:07:06.456175+00:00, run_duration=0.169985, state=success, executor_state=success, try_number=12, max_tries=12, job_id=3189, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:06:56.949266+00:00, queued_by_job_id=3032, pid=366803[0m
[[34m2024-07-30T11:07:16.638+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:07:16.063910+00:00, run_end_date=2024-07-30 02:07:16.186552+00:00, run_duration=0.122642, state=success, executor_state=success, try_number=8, max_tries=8, job_id=3193, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:06:56.949266+00:00, queued_by_job_id=3032, pid=366854[0m
[[34m2024-07-30T11:07:16.638+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:07:03.832593+00:00, run_end_date=2024-07-30 02:07:04.012736+00:00, run_duration=0.180143, state=success, executor_state=success, try_number=12, max_tries=12, job_id=3188, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:06:56.949266+00:00, queued_by_job_id=3032, pid=366791[0m
[[34m2024-07-30T11:07:16.638+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:07:13.506593+00:00, run_end_date=2024-07-30 02:07:13.616226+00:00, run_duration=0.109633, state=success, executor_state=success, try_number=8, max_tries=8, job_id=3192, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:06:56.949266+00:00, queued_by_job_id=3032, pid=366841[0m
[[34m2024-07-30T11:08:45.497+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:09:13.660+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 8 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:09:13.660+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T11:09:13.660+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:09:13.660+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:09:13.661+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:09:13.661+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T11:09:13.661+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-30T11:09:13.661+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-30T11:09:13.661+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T11:09:13.661+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:09:13.663+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=13, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:09:13.663+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:13.663+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=13, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:09:13.663+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:13.663+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=13, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:09:13.663+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:13.663+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=13, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:09:13.664+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:13.664+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=9, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:09:13.664+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:13.664+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=9, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:09:13.664+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:13.664+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=9, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:09:13.664+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:13.664+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=9, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:09:13.665+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:13.671+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:14.712+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:09:14.787+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:14.825+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:09:14.825+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:15.292+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:09:15.950+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:17.073+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:09:17.144+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:17.180+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:09:17.181+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:17.643+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:09:18.290+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:19.350+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:09:19.432+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:19.470+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:09:19.470+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:19.955+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:09:20.639+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:21.665+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:09:21.751+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:21.793+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:09:21.793+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:22.265+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:09:22.934+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:24.099+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:09:24.179+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:24.219+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:09:24.219+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:24.720+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:09:25.348+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:26.394+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:09:26.467+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:26.503+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:09:26.504+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:26.983+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:09:27.621+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:28.698+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:09:28.773+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:28.815+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:09:28.815+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:29.265+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:09:29.972+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:09:31.061+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:09:31.161+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:31.205+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:09:31.206+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:09:31.708+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:09:32.326+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=13, map_index=-1)[0m
[[34m2024-07-30T11:09:32.326+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=13, map_index=-1)[0m
[[34m2024-07-30T11:09:32.326+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=13, map_index=-1)[0m
[[34m2024-07-30T11:09:32.326+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=13, map_index=-1)[0m
[[34m2024-07-30T11:09:32.326+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=9, map_index=-1)[0m
[[34m2024-07-30T11:09:32.326+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=9, map_index=-1)[0m
[[34m2024-07-30T11:09:32.327+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=9, map_index=-1)[0m
[[34m2024-07-30T11:09:32.327+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=9, map_index=-1)[0m
[[34m2024-07-30T11:09:32.330+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:09:15.337533+00:00, run_end_date=2024-07-30 02:09:15.503724+00:00, run_duration=0.166191, state=success, executor_state=success, try_number=13, max_tries=13, job_id=3194, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:09:13.662057+00:00, queued_by_job_id=3032, pid=367267[0m
[[34m2024-07-30T11:09:32.330+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:09:24.797899+00:00, run_end_date=2024-07-30 02:09:24.904461+00:00, run_duration=0.106562, state=success, executor_state=success, try_number=9, max_tries=9, job_id=3198, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:09:13.662057+00:00, queued_by_job_id=3032, pid=367317[0m
[[34m2024-07-30T11:09:32.331+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:09:17.688697+00:00, run_end_date=2024-07-30 02:09:17.844714+00:00, run_duration=0.156017, state=success, executor_state=success, try_number=13, max_tries=13, job_id=3195, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:09:13.662057+00:00, queued_by_job_id=3032, pid=367279[0m
[[34m2024-07-30T11:09:32.331+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:09:27.038981+00:00, run_end_date=2024-07-30 02:09:27.175015+00:00, run_duration=0.136034, state=success, executor_state=success, try_number=9, max_tries=9, job_id=3199, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:09:13.662057+00:00, queued_by_job_id=3032, pid=367329[0m
[[34m2024-07-30T11:09:32.331+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:09:22.311620+00:00, run_end_date=2024-07-30 02:09:22.470560+00:00, run_duration=0.15894, state=success, executor_state=success, try_number=13, max_tries=13, job_id=3197, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:09:13.662057+00:00, queued_by_job_id=3032, pid=367304[0m
[[34m2024-07-30T11:09:32.331+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:09:31.759556+00:00, run_end_date=2024-07-30 02:09:31.870603+00:00, run_duration=0.111047, state=success, executor_state=success, try_number=9, max_tries=9, job_id=3201, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:09:13.662057+00:00, queued_by_job_id=3032, pid=367354[0m
[[34m2024-07-30T11:09:32.331+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:09:20.008133+00:00, run_end_date=2024-07-30 02:09:20.166770+00:00, run_duration=0.158637, state=success, executor_state=success, try_number=13, max_tries=13, job_id=3196, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:09:13.662057+00:00, queued_by_job_id=3032, pid=367292[0m
[[34m2024-07-30T11:09:32.331+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:09:29.335536+00:00, run_end_date=2024-07-30 02:09:29.501236+00:00, run_duration=0.1657, state=success, executor_state=success, try_number=9, max_tries=9, job_id=3200, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:09:13.662057+00:00, queued_by_job_id=3032, pid=367341[0m
[[34m2024-07-30T11:09:32.487+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-28 04:10:00+00:00: scheduled__2024-07-28T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:09:13.378695+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:09:32.487+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-28 04:10:00+00:00, run_id=scheduled__2024-07-28T04:10:00+00:00, run_start_date=2024-07-30 02:09:13.551826+00:00, run_end_date=2024-07-30 02:09:32.487320+00:00, run_duration=18.935494, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-28 04:10:00+00:00, data_interval_end=2024-07-29 04:10:00+00:00, dag_hash=da60cd1eb76d407040187b79fbec32c8[0m
[[34m2024-07-30T11:09:32.489+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:12:47.217+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:12:33.554689+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:12:47.218+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-30 02:12:33.829121+00:00, run_end_date=2024-07-30 02:12:47.218291+00:00, run_duration=13.38917, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=5fc168f1e4d988bda97898389ab0fa96[0m
[[34m2024-07-30T11:12:47.220+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-30T11:12:48.362+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T11:12:49.277+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T11:12:49.294+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:12:33.554740+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:12:49.294+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-30 02:12:33.829164+00:00, run_end_date=2024-07-30 02:12:49.294346+00:00, run_duration=15.465182, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=5fc168f1e4d988bda97898389ab0fa96[0m
[[34m2024-07-30T11:12:49.296+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T11:12:50.455+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T11:12:51.622+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:12:51.641+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:12:33.554756+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:12:51.642+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-30 02:12:33.829178+00:00, run_end_date=2024-07-30 02:12:51.642226+00:00, run_duration=17.813048, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=5fc168f1e4d988bda97898389ab0fa96[0m
[[34m2024-07-30T11:12:51.644+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T11:12:52.785+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:13:45.633+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:17:04.243+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 8 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:17:04.244+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T11:17:04.244+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:17:04.244+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:17:04.244+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:17:04.244+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T11:17:04.244+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-30T11:17:04.244+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-30T11:17:04.244+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T11:17:04.245+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:17:04.246+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=15, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:17:04.247+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:04.247+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=15, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:17:04.247+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:04.247+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=15, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:17:04.247+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:04.248+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=15, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:17:04.248+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:04.248+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=11, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:17:04.249+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:04.249+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=11, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:17:04.249+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:04.249+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=11, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:17:04.249+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:04.249+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=11, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:17:04.250+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:04.259+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:05.341+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:17:05.413+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:05.453+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:17:05.454+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:05.937+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:17:06.592+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:07.813+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:17:07.904+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:07.943+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:17:07.944+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:08.442+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:17:09.099+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:10.147+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:17:10.227+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:10.267+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:17:10.268+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:10.743+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:17:11.424+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:12.528+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:17:12.613+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:12.656+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:17:12.656+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:13.140+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:17:13.802+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:14.890+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:17:14.985+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:15.027+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:17:15.027+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:15.572+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:17:16.158+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:17.239+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:17:17.328+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:17.366+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:17:17.366+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:17.827+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:17:18.445+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:19.626+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:17:19.712+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:19.754+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:17:19.754+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:20.226+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:17:20.842+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:17:21.873+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:17:21.961+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:22.006+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:17:22.007+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:17:22.540+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:17:23.191+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=15, map_index=-1)[0m
[[34m2024-07-30T11:17:23.191+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=15, map_index=-1)[0m
[[34m2024-07-30T11:17:23.191+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=15, map_index=-1)[0m
[[34m2024-07-30T11:17:23.191+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=15, map_index=-1)[0m
[[34m2024-07-30T11:17:23.192+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=11, map_index=-1)[0m
[[34m2024-07-30T11:17:23.192+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=11, map_index=-1)[0m
[[34m2024-07-30T11:17:23.192+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=11, map_index=-1)[0m
[[34m2024-07-30T11:17:23.192+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=11, map_index=-1)[0m
[[34m2024-07-30T11:17:23.195+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:17:05.981214+00:00, run_end_date=2024-07-30 02:17:06.140389+00:00, run_duration=0.159175, state=success, executor_state=success, try_number=15, max_tries=15, job_id=3210, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:17:04.245758+00:00, queued_by_job_id=3032, pid=368702[0m
[[34m2024-07-30T11:17:23.196+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:17:15.618395+00:00, run_end_date=2024-07-30 02:17:15.725529+00:00, run_duration=0.107134, state=success, executor_state=success, try_number=11, max_tries=11, job_id=3214, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:17:04.245758+00:00, queued_by_job_id=3032, pid=368755[0m
[[34m2024-07-30T11:17:23.196+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:17:08.501112+00:00, run_end_date=2024-07-30 02:17:08.660257+00:00, run_duration=0.159145, state=success, executor_state=success, try_number=15, max_tries=15, job_id=3211, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:17:04.245758+00:00, queued_by_job_id=3032, pid=368716[0m
[[34m2024-07-30T11:17:23.196+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:17:17.882683+00:00, run_end_date=2024-07-30 02:17:17.995176+00:00, run_duration=0.112493, state=success, executor_state=success, try_number=11, max_tries=11, job_id=3215, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:17:04.245758+00:00, queued_by_job_id=3032, pid=368767[0m
[[34m2024-07-30T11:17:23.196+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:17:13.187375+00:00, run_end_date=2024-07-30 02:17:13.347639+00:00, run_duration=0.160264, state=success, executor_state=success, try_number=15, max_tries=15, job_id=3213, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:17:04.245758+00:00, queued_by_job_id=3032, pid=368742[0m
[[34m2024-07-30T11:17:23.196+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:17:22.595786+00:00, run_end_date=2024-07-30 02:17:22.714832+00:00, run_duration=0.119046, state=success, executor_state=success, try_number=11, max_tries=11, job_id=3217, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:17:04.245758+00:00, queued_by_job_id=3032, pid=368791[0m
[[34m2024-07-30T11:17:23.196+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:17:10.790132+00:00, run_end_date=2024-07-30 02:17:10.960019+00:00, run_duration=0.169887, state=success, executor_state=success, try_number=15, max_tries=15, job_id=3212, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:17:04.245758+00:00, queued_by_job_id=3032, pid=368730[0m
[[34m2024-07-30T11:17:23.196+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:17:20.278316+00:00, run_end_date=2024-07-30 02:17:20.391336+00:00, run_duration=0.11302, state=success, executor_state=success, try_number=11, max_tries=11, job_id=3216, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:17:04.245758+00:00, queued_by_job_id=3032, pid=368779[0m
[[34m2024-07-30T11:17:23.342+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-28 04:10:00+00:00: scheduled__2024-07-28T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:17:03.275145+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:17:23.342+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-28 04:10:00+00:00, run_id=scheduled__2024-07-28T04:10:00+00:00, run_start_date=2024-07-30 02:17:03.503439+00:00, run_end_date=2024-07-30 02:17:23.342937+00:00, run_duration=19.839498, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-28 04:10:00+00:00, data_interval_end=2024-07-29 04:10:00+00:00, dag_hash=516059022aead21924341a252bef9fa1[0m
[[34m2024-07-30T11:17:23.345+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:18:45.662+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:19:03.407+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 8 tasks up for execution:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:19:03.407+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T11:19:03.407+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:19:03.407+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:19:03.407+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:19:03.408+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T11:19:03.408+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 5/16 running and queued tasks[0m
[[34m2024-07-30T11:19:03.408+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-30T11:19:03.408+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T11:19:03.408+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:19:03.410+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=16, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:19:03.410+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:03.410+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=16, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:19:03.410+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:03.410+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=16, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:19:03.410+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:03.410+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=16, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-30T11:19:03.410+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:03.411+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=12, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:19:03.411+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:03.411+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=12, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:19:03.411+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:03.411+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=12, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:19:03.411+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:03.411+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=12, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:19:03.411+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:03.421+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:04.434+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:19:04.513+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:04.549+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:19:04.550+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:05.050+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:19:05.704+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:06.863+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:19:06.936+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:06.976+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:19:06.977+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:07.451+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:19:08.088+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:09.155+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:19:09.231+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:09.273+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:19:09.273+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:09.771+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:19:10.429+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'branch.op', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:11.506+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:19:11.585+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:11.625+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:19:11.625+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:12.111+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.branch.op scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:19:12.768+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:13.935+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:19:14.026+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:14.071+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:19:14.071+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:14.542+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:19:15.160+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:16.211+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:19:16.288+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:16.328+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:19:16.328+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:16.826+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:19:17.434+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:18.524+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:19:18.607+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:18.650+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:19:18.650+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:19.182+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:19:19.784+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'print_the_context', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:19:20.947+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:19:21.043+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:21.083+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:19:21.083+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:19:21.565+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.print_the_context scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:19:22.159+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=16, map_index=-1)[0m
[[34m2024-07-30T11:19:22.160+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=16, map_index=-1)[0m
[[34m2024-07-30T11:19:22.160+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=16, map_index=-1)[0m
[[34m2024-07-30T11:19:22.160+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='branch.op', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=16, map_index=-1)[0m
[[34m2024-07-30T11:19:22.160+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=12, map_index=-1)[0m
[[34m2024-07-30T11:19:22.160+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=12, map_index=-1)[0m
[[34m2024-07-30T11:19:22.160+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=12, map_index=-1)[0m
[[34m2024-07-30T11:19:22.161+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='print_the_context', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=12, map_index=-1)[0m
[[34m2024-07-30T11:19:22.164+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:19:05.096505+00:00, run_end_date=2024-07-30 02:19:05.264819+00:00, run_duration=0.168314, state=success, executor_state=success, try_number=16, max_tries=16, job_id=3218, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:19:03.409027+00:00, queued_by_job_id=3032, pid=369104[0m
[[34m2024-07-30T11:19:22.164+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:19:14.587196+00:00, run_end_date=2024-07-30 02:19:14.693504+00:00, run_duration=0.106308, state=success, executor_state=success, try_number=12, max_tries=12, job_id=3222, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:19:03.409027+00:00, queued_by_job_id=3032, pid=369156[0m
[[34m2024-07-30T11:19:22.165+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:19:07.496623+00:00, run_end_date=2024-07-30 02:19:07.651361+00:00, run_duration=0.154738, state=success, executor_state=success, try_number=16, max_tries=16, job_id=3219, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:19:03.409027+00:00, queued_by_job_id=3032, pid=369116[0m
[[34m2024-07-30T11:19:22.165+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:19:16.881195+00:00, run_end_date=2024-07-30 02:19:16.997233+00:00, run_duration=0.116038, state=success, executor_state=success, try_number=12, max_tries=12, job_id=3223, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:19:03.409027+00:00, queued_by_job_id=3032, pid=369168[0m
[[34m2024-07-30T11:19:22.165+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:19:12.156142+00:00, run_end_date=2024-07-30 02:19:12.308267+00:00, run_duration=0.152125, state=success, executor_state=success, try_number=16, max_tries=16, job_id=3221, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:19:03.409027+00:00, queued_by_job_id=3032, pid=369144[0m
[[34m2024-07-30T11:19:22.165+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:19:21.616629+00:00, run_end_date=2024-07-30 02:19:21.731961+00:00, run_duration=0.115332, state=success, executor_state=success, try_number=12, max_tries=12, job_id=3225, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:19:03.409027+00:00, queued_by_job_id=3032, pid=369193[0m
[[34m2024-07-30T11:19:22.165+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=branch.op, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:19:09.818564+00:00, run_end_date=2024-07-30 02:19:09.976704+00:00, run_duration=0.15814, state=success, executor_state=success, try_number=16, max_tries=16, job_id=3220, pool=default_pool, queue=default, priority_weight=8, operator=BranchPythonOperator, queued_dttm=2024-07-30 02:19:03.409027+00:00, queued_by_job_id=3032, pid=369131[0m
[[34m2024-07-30T11:19:22.165+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=print_the_context, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:19:19.233824+00:00, run_end_date=2024-07-30 02:19:19.343780+00:00, run_duration=0.109956, state=success, executor_state=success, try_number=12, max_tries=12, job_id=3224, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-30 02:19:03.409027+00:00, queued_by_job_id=3032, pid=369181[0m
[[34m2024-07-30T11:19:22.312+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:22:48.050+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:22:48.051+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T11:22:48.051+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:22:48.053+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T11:22:48.053+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:22:48.060+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:22:49.566+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:22:49.648+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:22:49.693+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:22:49.693+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:22:50.313+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:23:21.540+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:23:21.543+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:22:50.376489+00:00, run_end_date=2024-07-30 02:23:21.077226+00:00, run_duration=30.700737, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3228, pool=default_pool, queue=default, priority_weight=5, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 02:22:48.051957+00:00, queued_by_job_id=3032, pid=369754[0m
[[34m2024-07-30T11:23:21.754+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:21.754+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:23:21.754+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:21.756+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-30T11:23:21.756+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:21.766+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:23.259+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:23:23.366+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:23.425+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:23:23.426+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:24.000+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:23:24.733+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:23:24.736+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:23:24.058238+00:00, run_end_date=2024-07-30 02:23:24.237407+00:00, run_duration=0.179169, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3236, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2024-07-30 02:23:21.755310+00:00, queued_by_job_id=3032, pid=369950[0m
[[34m2024-07-30T11:23:24.900+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:24.901+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:23:24.901+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T11:23:24.901+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:24.902+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:23:24.902+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:24.902+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:23:24.902+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:24.912+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:26.421+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:23:26.525+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:26.580+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:23:26.580+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:27.145+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:23:27.905+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:29.064+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:23:29.196+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:29.268+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:23:29.269+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:30.039+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:23:30.777+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:23:30.777+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:23:30.782+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:23:27.273339+00:00, run_end_date=2024-07-30 02:23:27.463028+00:00, run_duration=0.189689, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3237, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:23:24.901735+00:00, queued_by_job_id=3032, pid=369971[0m
[[34m2024-07-30T11:23:30.782+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:23:30.125252+00:00, run_end_date=2024-07-30 02:23:30.290110+00:00, run_duration=0.164858, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3238, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:23:24.901735+00:00, queued_by_job_id=3032, pid=369986[0m
[[34m2024-07-30T11:23:31.059+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:31.059+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:23:31.059+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:31.060+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-30T11:23:31.061+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:31.069+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:32.472+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:23:32.606+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:32.665+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:23:32.665+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:33.276+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:23:34.106+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:23:34.109+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:23:33.346237+00:00, run_end_date=2024-07-30 02:23:33.583455+00:00, run_duration=0.237218, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3240, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2024-07-30 02:23:31.060243+00:00, queued_by_job_id=3032, pid=370015[0m
[[34m2024-07-30T11:23:34.350+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:22:44.296836+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:23:34.350+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-30 02:22:44.602993+00:00, run_end_date=2024-07-30 02:23:34.350745+00:00, run_duration=49.747752, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=0aa47d12a4b4f7b2b30b55c877d5a49b[0m
[[34m2024-07-30T11:23:34.354+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-30T11:23:34.377+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.c scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:34.377+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:23:34.377+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:23:34.377+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.c scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:34.378+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:23:34.378+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:34.378+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:23:34.379+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:34.389+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:35.662+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:23:35.744+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:35.791+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:23:35.791+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:36.390+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:23:37.285+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:38.729+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:23:38.831+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:38.878+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:23:38.879+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:39.462+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:23:40.241+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:23:40.242+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:23:40.245+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:23:36.461589+00:00, run_end_date=2024-07-30 02:23:36.650645+00:00, run_duration=0.189056, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3241, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:23:34.378089+00:00, queued_by_job_id=3032, pid=370063[0m
[[34m2024-07-30T11:23:40.245+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:23:39.521086+00:00, run_end_date=2024-07-30 02:23:39.723274+00:00, run_duration=0.202188, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3242, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:23:34.378089+00:00, queued_by_job_id=3032, pid=370078[0m
[[34m2024-07-30T11:23:40.492+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T11:23:41.668+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T11:23:41.691+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:22:44.296868+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:23:41.691+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-30 02:22:44.603067+00:00, run_end_date=2024-07-30 02:23:41.691842+00:00, run_duration=57.088775, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=0aa47d12a4b4f7b2b30b55c877d5a49b[0m
[[34m2024-07-30T11:23:41.694+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T11:23:42.843+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T11:23:44.016+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:23:45.919+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:23:45.922+0900[0m] {[34mscheduler_job_runner.py:[0m1621} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[[34m2024-07-30T11:23:45.925+0900[0m] {[34mscheduler_job_runner.py:[0m1657} INFO[0m - Reset the following 2 orphaned TaskInstances:
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [queued]>
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [running]>[0m
[[34m2024-07-30T11:23:47.082+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:47.083+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T11:23:47.083+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:23:47.083+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:23:47.084+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=5, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T11:23:47.084+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:47.085+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T11:23:47.085+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:47.097+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:23:48.496+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:23:48.616+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:48.680+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:23:48.681+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:23:49.367+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:24:00.173+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:24:01.618+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:24:01.720+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:01.767+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:24:01.767+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:02.337+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [running]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:24:02.804+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=5, map_index=-1)[0m
[[34m2024-07-30T11:24:02.805+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:24:02.808+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:23:49.441603+00:00, run_end_date=2024-07-30 02:23:50.903593+00:00, run_duration=1.46199, state=success, executor_state=success, try_number=5, max_tries=4, job_id=3243, pool=default_pool, queue=default, priority_weight=5, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 02:23:47.083772+00:00, queued_by_job_id=3032, pid=370100[0m
[[34m2024-07-30T11:24:02.808+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:23:53.676276+00:00, run_end_date=None, run_duration=19.252715, state=running, executor_state=success, try_number=4, max_tries=4, job_id=3244, pool=default_pool, queue=default, priority_weight=5, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 02:23:47.083772+00:00, queued_by_job_id=3032, pid=370165[0m
[[34m2024-07-30T11:24:02.990+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:24:02.991+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:24:02.991+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:24:02.992+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-30T11:24:02.993+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:24:03.005+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:24:04.484+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:24:04.605+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:04.659+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:24:04.660+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:05.243+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:24:06.022+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:24:06.026+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:24:05.306560+00:00, run_end_date=2024-07-30 02:24:05.490333+00:00, run_duration=0.183773, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3246, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2024-07-30 02:24:02.991805+00:00, queued_by_job_id=3032, pid=370237[0m
[[34m2024-07-30T11:24:06.183+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:24:06.183+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:24:06.184+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:24:06.184+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:24:06.185+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:24:06.185+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:24:06.185+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:24:06.185+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:24:06.199+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:24:07.573+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:24:07.692+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:07.746+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:24:07.747+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:08.482+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:24:09.259+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:24:10.771+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:24:10.859+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:10.914+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:24:10.914+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:11.465+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:24:12.199+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:24:12.200+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:24:12.205+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:24:08.558195+00:00, run_end_date=2024-07-30 02:24:08.733075+00:00, run_duration=0.17488, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3247, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:24:06.184498+00:00, queued_by_job_id=3032, pid=370249[0m
[[34m2024-07-30T11:24:12.205+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:24:11.520879+00:00, run_end_date=2024-07-30 02:24:11.700632+00:00, run_duration=0.179753, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3248, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:24:06.184498+00:00, queued_by_job_id=3032, pid=370260[0m
[[34m2024-07-30T11:24:12.961+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:22:44.296880+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:24:12.961+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-30 02:22:44.603080+00:00, run_end_date=2024-07-30 02:24:12.961493+00:00, run_duration=88.358413, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=0aa47d12a4b4f7b2b30b55c877d5a49b[0m
[[34m2024-07-30T11:24:12.963+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T11:24:14.122+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:24:15.725+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:24:15.725+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T11:24:15.725+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:24:15.727+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-30T11:24:15.727+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:24:15.735+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:24:17.036+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:24:17.110+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:17.146+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:24:17.146+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:24:17.606+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:24:18.303+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:24:18.307+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:24:17.655927+00:00, run_end_date=2024-07-30 02:24:17.816561+00:00, run_duration=0.160634, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3249, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2024-07-30 02:24:15.726340+00:00, queued_by_job_id=3032, pid=370290[0m
[[34m2024-07-30T11:24:23.033+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-28 04:10:00+00:00: scheduled__2024-07-28T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:22:44.296905+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:24:23.033+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-28 04:10:00+00:00, run_id=scheduled__2024-07-28T04:10:00+00:00, run_start_date=2024-07-30 02:22:44.603092+00:00, run_end_date=2024-07-30 02:24:23.033747+00:00, run_duration=98.430655, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-28 04:10:00+00:00, data_interval_end=2024-07-29 04:10:00+00:00, dag_hash=067ef75da275e4e5056c45f58deed1be[0m
[[34m2024-07-30T11:24:23.036+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:28:46.191+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:31:04.042+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.rm.dir scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:31:04.042+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T11:31:04.042+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.rm.dir scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:31:04.043+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2024-07-30T11:31:04.043+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:04.055+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:05.394+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:31:05.496+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:31:05.567+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:31:05.568+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:31:06.187+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.rm.dir scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:31:06.904+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:31:06.907+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=rm.dir, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:31:06.259797+00:00, run_end_date=2024-07-30 02:31:06.427403+00:00, run_duration=0.167606, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3254, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2024-07-30 02:31:04.042929+00:00, queued_by_job_id=3032, pid=371261[0m
[[34m2024-07-30T11:31:07.192+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.rm.dir scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:31:07.192+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 6/16 running and queued tasks[0m
[[34m2024-07-30T11:31:07.192+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T11:31:07.192+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.rm.dir scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:31:07.194+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=4, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2024-07-30T11:31:07.194+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:07.194+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=5, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T11:31:07.195+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:07.204+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'rm.dir', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:08.468+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:31:08.561+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:31:08.607+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:31:08.607+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:31:09.190+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.rm.dir scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:31:10.022+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:11.253+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:31:11.350+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:31:11.394+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:31:11.394+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:31:11.939+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:31:36.453+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='rm.dir', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-30T11:31:36.453+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=5, map_index=-1)[0m
[[34m2024-07-30T11:31:36.457+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:31:11.995277+00:00, run_end_date=2024-07-30 02:31:35.889745+00:00, run_duration=23.894468, state=success, executor_state=success, try_number=5, max_tries=5, job_id=3258, pool=default_pool, queue=default, priority_weight=5, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 02:31:07.193355+00:00, queued_by_job_id=3032, pid=371310[0m
[[34m2024-07-30T11:31:36.458+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=rm.dir, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:31:09.253230+00:00, run_end_date=2024-07-30 02:31:09.441456+00:00, run_duration=0.188226, state=success, executor_state=success, try_number=4, max_tries=4, job_id=3256, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2024-07-30 02:31:07.193355+00:00, queued_by_job_id=3032, pid=371287[0m
[[34m2024-07-30T11:31:36.757+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 3 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.save.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:31:36.757+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:31:36.757+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:31:36.757+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:31:36.757+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.save.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:31:36.759+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T11:31:36.759+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:36.759+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=5, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T11:31:36.759+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:36.759+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=5, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-30T11:31:36.759+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:36.768+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:31:38.103+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:31:38.220+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:31:38.282+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:31:38.283+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:31:39.015+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:32:00.007+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:01.537+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:32:01.678+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:01.721+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:32:01.722+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:02.300+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:32:21.129+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:22.514+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:32:22.670+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:22.743+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:32:22.744+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:23.335+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:32:24.086+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:32:24.086+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=5, map_index=-1)[0m
[[34m2024-07-30T11:32:24.087+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=5, map_index=-1)[0m
[[34m2024-07-30T11:32:24.109+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:31:39.089581+00:00, run_end_date=2024-07-30 02:31:59.447067+00:00, run_duration=20.357486, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3266, pool=default_pool, queue=default, priority_weight=5, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 02:31:36.758102+00:00, queued_by_job_id=3032, pid=371509[0m
[[34m2024-07-30T11:32:24.110+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:32:23.402160+00:00, run_end_date=2024-07-30 02:32:23.556391+00:00, run_duration=0.154231, state=success, executor_state=success, try_number=5, max_tries=5, job_id=3274, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2024-07-30 02:31:36.758102+00:00, queued_by_job_id=3032, pid=371757[0m
[[34m2024-07-30T11:32:24.110+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:32:02.387147+00:00, run_end_date=2024-07-30 02:32:20.692067+00:00, run_duration=18.30492, state=success, executor_state=success, try_number=5, max_tries=5, job_id=3271, pool=default_pool, queue=default, priority_weight=5, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 02:31:36.758102+00:00, queued_by_job_id=3032, pid=371637[0m
[[34m2024-07-30T11:32:24.287+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.c scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:32:24.287+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T11:32:24.287+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:32:24.287+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:32:24.287+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:32:24.288+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.c scheduled__2024-07-28T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:32:24.291+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=5, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:32:24.291+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:24.291+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=5, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:32:24.292+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:24.292+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=5, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:32:24.292+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:24.292+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=5, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:32:24.292+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:24.300+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:25.475+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:32:25.557+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:25.603+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:32:25.603+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:26.203+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:32:26.863+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:28.103+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:32:28.183+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:28.238+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:32:28.239+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:28.740+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:32:29.413+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:30.661+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:32:30.753+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:30.800+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:32:30.801+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:31.307+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:32:31.977+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:32:33.110+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:32:33.219+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:33.275+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:32:33.276+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:32:34.078+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:32:34.817+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=5, map_index=-1)[0m
[[34m2024-07-30T11:32:34.817+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=5, map_index=-1)[0m
[[34m2024-07-30T11:32:34.817+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=5, map_index=-1)[0m
[[34m2024-07-30T11:32:34.818+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=5, map_index=-1)[0m
[[34m2024-07-30T11:32:34.828+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:32:26.254817+00:00, run_end_date=2024-07-30 02:32:26.406108+00:00, run_duration=0.151291, state=success, executor_state=success, try_number=5, max_tries=5, job_id=3276, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:32:24.288521+00:00, queued_by_job_id=3032, pid=371774[0m
[[34m2024-07-30T11:32:34.828+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:32:28.789536+00:00, run_end_date=2024-07-30 02:32:28.938414+00:00, run_duration=0.148878, state=success, executor_state=success, try_number=5, max_tries=5, job_id=3277, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:32:24.288521+00:00, queued_by_job_id=3032, pid=371787[0m
[[34m2024-07-30T11:32:34.828+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:32:31.357817+00:00, run_end_date=2024-07-30 02:32:31.507289+00:00, run_duration=0.149472, state=success, executor_state=success, try_number=5, max_tries=5, job_id=3278, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:32:24.288521+00:00, queued_by_job_id=3032, pid=371801[0m
[[34m2024-07-30T11:32:34.829+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:32:34.154422+00:00, run_end_date=2024-07-30 02:32:34.334794+00:00, run_duration=0.180372, state=success, executor_state=success, try_number=5, max_tries=5, job_id=3279, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:32:24.288521+00:00, queued_by_job_id=3032, pid=371814[0m
[[34m2024-07-30T11:33:46.296+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:38:46.433+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:43:46.570+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:46:37.166+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:46:37.166+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 7/16 running and queued tasks[0m
[[34m2024-07-30T11:46:37.166+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:46:37.168+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-30T11:46:37.168+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:46:37.177+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'get.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:46:38.436+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:46:38.529+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:46:38.573+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:46:38.574+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:46:39.123+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.get.data scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:46:59.470+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='get.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:46:59.474+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=get.data, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:46:39.177949+00:00, run_end_date=2024-07-30 02:46:58.941770+00:00, run_duration=19.763821, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3281, pool=default_pool, queue=default, priority_weight=5, operator=PythonVirtualenvOperator, queued_dttm=2024-07-30 02:46:37.167103+00:00, queued_by_job_id=3032, pid=373755[0m
[[34m2024-07-30T11:46:59.686+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:46:59.686+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:46:59.687+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:46:59.688+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-30T11:46:59.688+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:46:59.698+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:01.131+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:47:01.231+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:01.278+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:47:01.278+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:01.835+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:47:02.451+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:47:02.455+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:47:01.885434+00:00, run_end_date=2024-07-30 02:47:02.024807+00:00, run_duration=0.139373, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3290, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2024-07-30 02:46:59.687590+00:00, queued_by_job_id=3032, pid=373916[0m
[[34m2024-07-30T11:47:02.615+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:02.616+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:47:02.616+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 4/16 running and queued tasks[0m
[[34m2024-07-30T11:47:02.616+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:02.617+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:47:02.617+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:02.617+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:47:02.617+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:02.626+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:03.906+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:47:04.028+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:04.077+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:47:04.078+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:04.640+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:47:05.408+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-25T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:06.684+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:47:06.771+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:06.819+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:47:06.819+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:07.452+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-25T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:47:08.161+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:47:08.161+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-25T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:47:08.164+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:47:04.703954+00:00, run_end_date=2024-07-30 02:47:04.878108+00:00, run_duration=0.174154, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3291, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:47:02.616578+00:00, queued_by_job_id=3032, pid=373956[0m
[[34m2024-07-30T11:47:08.164+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-25T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:47:07.518078+00:00, run_end_date=2024-07-30 02:47:07.686502+00:00, run_duration=0.168424, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3292, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:47:02.616578+00:00, queued_by_job_id=3032, pid=373969[0m
[[34m2024-07-30T11:47:09.685+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-25 04:10:00+00:00: scheduled__2024-07-25T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:46:33.876605+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:47:09.685+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-25 04:10:00+00:00, run_id=scheduled__2024-07-25T04:10:00+00:00, run_start_date=2024-07-30 02:46:34.708870+00:00, run_end_date=2024-07-30 02:47:09.685723+00:00, run_duration=34.976853, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 04:10:00+00:00, data_interval_end=2024-07-26 04:10:00+00:00, dag_hash=067ef75da275e4e5056c45f58deed1be[0m
[[34m2024-07-30T11:47:09.689+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-26 04:10:00+00:00, run_after=2024-07-27 04:10:00+00:00[0m
[[34m2024-07-30T11:47:10.853+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T11:47:12.026+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T11:47:13.203+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:47:19.475+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:19.475+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:47:19.475+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:19.477+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-30T11:47:19.478+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:19.485+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:20.900+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:47:20.987+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:21.046+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:47:21.047+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:21.623+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:47:22.487+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:47:22.491+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:47:21.697216+00:00, run_end_date=2024-07-30 02:47:21.888613+00:00, run_duration=0.191397, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3294, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2024-07-30 02:47:19.476441+00:00, queued_by_job_id=3032, pid=374026[0m
[[34m2024-07-30T11:47:22.657+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.c scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:22.658+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:47:22.658+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 3/16 running and queued tasks[0m
[[34m2024-07-30T11:47:22.659+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.c scheduled__2024-07-26T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-26T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:22.661+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:47:22.661+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:22.662+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:47:22.662+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:22.668+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:23.880+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:47:23.960+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:24.000+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:47:24.000+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:24.482+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:47:25.113+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-26T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:26.622+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:47:26.723+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:26.761+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:47:26.761+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:27.357+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-26T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:47:28.039+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:47:28.039+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-26T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:47:28.042+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:47:24.536862+00:00, run_end_date=2024-07-30 02:47:24.679160+00:00, run_duration=0.142298, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3295, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:47:22.660168+00:00, queued_by_job_id=3032, pid=374066[0m
[[34m2024-07-30T11:47:28.042+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-26T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:47:27.424431+00:00, run_end_date=2024-07-30 02:47:27.590734+00:00, run_duration=0.166303, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3296, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:47:22.660168+00:00, queued_by_job_id=3032, pid=374087[0m
[[34m2024-07-30T11:47:29.345+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-26 04:10:00+00:00: scheduled__2024-07-26T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:46:33.876662+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:47:29.346+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-26 04:10:00+00:00, run_id=scheduled__2024-07-26T04:10:00+00:00, run_start_date=2024-07-30 02:46:34.708952+00:00, run_end_date=2024-07-30 02:47:29.346449+00:00, run_duration=54.637497, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 04:10:00+00:00, data_interval_end=2024-07-27 04:10:00+00:00, dag_hash=0aa47d12a4b4f7b2b30b55c877d5a49b[0m
[[34m2024-07-30T11:47:29.349+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-27 04:10:00+00:00, run_after=2024-07-28 04:10:00+00:00[0m
[[34m2024-07-30T11:47:29.806+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T11:47:30.985+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:47:40.822+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:40.823+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:47:40.823+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:40.825+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-30T11:47:40.825+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:40.832+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:42.421+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:47:42.546+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:42.610+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:47:42.611+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:43.222+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:47:43.991+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:47:43.995+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:47:43.289175+00:00, run_end_date=2024-07-30 02:47:43.479295+00:00, run_duration=0.19012, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3298, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2024-07-30 02:47:40.824409+00:00, queued_by_job_id=3032, pid=374146[0m
[[34m2024-07-30T11:47:44.168+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:44.168+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 1/16 running and queued tasks[0m
[[34m2024-07-30T11:47:44.169+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 2/16 running and queued tasks[0m
[[34m2024-07-30T11:47:44.169+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [scheduled]>
	<TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:47:44.171+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:47:44.171+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:44.171+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-30T11:47:44.171+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:44.182+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'c', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:45.525+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:47:45.625+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:45.676+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:47:45.677+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:46.184+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.c scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:47:46.909+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'd', 'scheduled__2024-07-27T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:47:48.364+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:47:48.472+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:48.526+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:47:48.527+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:47:49.218+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.d scheduled__2024-07-27T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:47:49.934+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='c', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:47:49.935+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='d', run_id='scheduled__2024-07-27T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:47:49.939+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=c, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:47:46.251279+00:00, run_end_date=2024-07-30 02:47:46.441288+00:00, run_duration=0.190009, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3299, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:47:44.169873+00:00, queued_by_job_id=3032, pid=374193[0m
[[34m2024-07-30T11:47:49.939+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=d, run_id=scheduled__2024-07-27T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:47:49.295827+00:00, run_end_date=2024-07-30 02:47:49.464719+00:00, run_duration=0.168892, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3300, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-07-30 02:47:44.169873+00:00, queued_by_job_id=3032, pid=374209[0m
[[34m2024-07-30T11:47:51.248+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-27 04:10:00+00:00: scheduled__2024-07-27T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:46:33.876674+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:47:51.248+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-27 04:10:00+00:00, run_id=scheduled__2024-07-27T04:10:00+00:00, run_start_date=2024-07-30 02:46:34.708968+00:00, run_end_date=2024-07-30 02:47:51.248711+00:00, run_duration=76.539743, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 04:10:00+00:00, data_interval_end=2024-07-28 04:10:00+00:00, dag_hash=0aa47d12a4b4f7b2b30b55c877d5a49b[0m
[[34m2024-07-30T11:47:51.252+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-28 04:10:00+00:00, run_after=2024-07-29 04:10:00+00:00[0m
[[34m2024-07-30T11:47:52.509+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:48:02.700+0900[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:48:02.700+0900[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG movie has 0/16 running and queued tasks[0m
[[34m2024-07-30T11:48:02.701+0900[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [scheduled]>[0m
[[34m2024-07-30T11:48:02.702+0900[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=6, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-30T11:48:02.702+0900[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:48:02.710+0900[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'movie', 'save.data', 'scheduled__2024-07-28T04:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/movie.py'][0m
[[34m2024-07-30T11:48:03.879+0900[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /home/michael/airflow/dags/movie.py[0m
[[34m2024-07-30T11:48:03.969+0900[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:48:04.016+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/michael/.pyenv/versions/air/lib/python3.11/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-07-30T11:48:04.017+0900[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-07-30T11:48:04.617+0900[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: movie.save.data scheduled__2024-07-28T04:10:00+00:00 [queued]> on host DESKTOP-G6PGQE2.[0m
[[34m2024-07-30T11:48:05.323+0900[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='movie', task_id='save.data', run_id='scheduled__2024-07-28T04:10:00+00:00', try_number=6, map_index=-1)[0m
[[34m2024-07-30T11:48:05.326+0900[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=movie, task_id=save.data, run_id=scheduled__2024-07-28T04:10:00+00:00, map_index=-1, run_start_date=2024-07-30 02:48:04.684506+00:00, run_end_date=2024-07-30 02:48:04.847602+00:00, run_duration=0.163096, state=success, executor_state=success, try_number=6, max_tries=6, job_id=3301, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2024-07-30 02:48:02.701374+00:00, queued_by_job_id=3032, pid=374250[0m
[[34m2024-07-30T11:48:10.627+0900[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun movie @ 2024-07-28 04:10:00+00:00: scheduled__2024-07-28T04:10:00+00:00, state:running, queued_at: 2024-07-30 02:46:33.876686+00:00. externally triggered: False> successful[0m
[[34m2024-07-30T11:48:10.627+0900[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=movie, execution_date=2024-07-28 04:10:00+00:00, run_id=scheduled__2024-07-28T04:10:00+00:00, run_start_date=2024-07-30 02:46:34.708981+00:00, run_end_date=2024-07-30 02:48:10.627871+00:00, run_duration=95.91889, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-28 04:10:00+00:00, data_interval_end=2024-07-29 04:10:00+00:00, dag_hash=067ef75da275e4e5056c45f58deed1be[0m
[[34m2024-07-30T11:48:10.630+0900[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for movie to 2024-07-29 04:10:00+00:00, run_after=2024-07-30 04:10:00+00:00[0m
[[34m2024-07-30T11:48:46.699+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:53:46.834+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T11:58:46.972+0900[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-30T12:02:22.448+0900[0m] {[34mscheduler_job_runner.py:[0m256} INFO[0m - Exiting gracefully upon receiving signal 15[0m
[[34m2024-07-30T12:02:23.454+0900[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 319327. PIDs of all processes in the group: [319327][0m
[[34m2024-07-30T12:02:23.455+0900[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 319327[0m
[[34m2024-07-30T12:02:23.589+0900[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Process psutil.Process(pid=319327, status='terminated', exitcode=0, started='18:47:32') (319327) terminated with exit code 0[0m
[[34m2024-07-30T12:02:23.592+0900[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 319327. PIDs of all processes in the group: [][0m
[[34m2024-07-30T12:02:23.592+0900[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 319327[0m
[[34m2024-07-30T12:02:23.592+0900[0m] {[34mprocess_utils.py:[0m101} INFO[0m - Sending the signal 15 to process 319327 as process group is missing.[0m
[[34m2024-07-30T12:02:23.593+0900[0m] {[34mscheduler_job_runner.py:[0m875} INFO[0m - Exited execute loop[0m
